{
  "openapi": "3.1.0",
  "info": {
    "title": "Doubao Seed 2.0 Complete API Reference",
    "description": "Complete API reference for Doubao Seed 2.0 chat interface, including all parameters and advanced features",
    "license": {
      "name": "MIT"
    },
    "version": "1.0.0"
  },
  "servers": [
    {
      "url": "https://api.evolink.ai",
      "description": "Production environment"
    }
  ],
  "security": [
    {
      "bearerAuth": []
    }
  ],
  "paths": {
    "/v1/chat/completions": {
      "post": {
        "summary": "Doubao Seed 2.0 Chat API",
        "description": "- Call Doubao Seed 2.0 series models using OpenAI SDK format\n- Synchronous processing mode, real-time response\n- **Text Chat**: Single or multi-turn contextual conversation\n- **System Prompts**: Customize AI role and behavior\n- **Multimodal Input**: Supports text + image + video mixed input\n- **Deep Thinking**: Supports enabling chain-of-thought mode for deep reasoning\n- **Tool Calling**: Function Calling support\n- **Structured Output**: Supports JSON Object / JSON Schema format output\n- Quick start? Check the [Quick Start Guide](./doubao-seed-2.0-quickstart)",
        "operationId": "createChatCompletionDoubaoSeed20",
        "tags": [
          "Chat Completion"
        ],
        "requestBody": {
          "required": true,
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/ChatCompletionRequest"
              },
              "examples": {
                "simple_text": {
                  "summary": "Simple text chat",
                  "value": {
                    "model": "doubao-seed-2.0-pro",
                    "messages": [
                      {
                        "role": "user",
                        "content": "Please introduce yourself"
                      }
                    ]
                  }
                },
                "multi_turn": {
                  "summary": "Multi-turn conversation (context understanding)",
                  "value": {
                    "model": "doubao-seed-2.0-pro",
                    "messages": [
                      {
                        "role": "user",
                        "content": "What is Python?"
                      },
                      {
                        "role": "assistant",
                        "content": "Python is a high-level programming language..."
                      },
                      {
                        "role": "user",
                        "content": "What are its advantages?"
                      }
                    ]
                  }
                },
                "system_prompt": {
                  "summary": "Using system prompt",
                  "value": {
                    "model": "doubao-seed-2.0-pro",
                    "messages": [
                      {
                        "role": "system",
                        "content": "You are a professional Python programming assistant, answer questions concisely."
                      },
                      {
                        "role": "user",
                        "content": "How to read a file?"
                      }
                    ]
                  }
                },
                "vision": {
                  "summary": "Multimodal input (text + image)",
                  "value": {
                    "model": "doubao-seed-2.0-pro",
                    "messages": [
                      {
                        "role": "user",
                        "content": [
                          {
                            "type": "text",
                            "text": "Please describe in detail the scene and main elements in this image."
                          },
                          {
                            "type": "image_url",
                            "image_url": {
                              "url": "https://example.com/image.png"
                            }
                          }
                        ]
                      }
                    ]
                  }
                },
                "thinking_mode": {
                  "summary": "Enable deep thinking mode",
                  "value": {
                    "model": "doubao-seed-2.0-pro",
                    "messages": [
                      {
                        "role": "user",
                        "content": "Prove that sqrt(2) is irrational"
                      }
                    ],
                    "thinking": {
                      "type": "enabled"
                    },
                    "max_completion_tokens": 16384
                  }
                },
                "code_generation": {
                  "summary": "Using code-specialized model",
                  "value": {
                    "model": "doubao-seed-2.0-code",
                    "messages": [
                      {
                        "role": "system",
                        "content": "You are an advanced programming assistant."
                      },
                      {
                        "role": "user",
                        "content": "Implement a quicksort algorithm in Python"
                      }
                    ]
                  }
                }
              }
            }
          }
        },
        "responses": {
          "200": {
            "description": "Chat completion successful",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ChatCompletionResponse"
                }
              }
            }
          },
          "400": {
            "description": "Invalid request parameters",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                },
                "example": {
                  "error": {
                    "code": 400,
                    "message": "Invalid request parameters",
                    "type": "invalid_request_error"
                  }
                }
              }
            }
          },
          "401": {
            "description": "Unauthenticated, invalid or expired token",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                },
                "example": {
                  "error": {
                    "code": 401,
                    "message": "Invalid or expired token",
                    "type": "authentication_error"
                  }
                }
              }
            }
          },
          "402": {
            "description": "Insufficient quota, top-up required",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                },
                "example": {
                  "error": {
                    "code": 402,
                    "message": "Insufficient quota",
                    "type": "insufficient_quota_error",
                    "fallback_suggestion": "https://evolink.ai/dashboard/billing"
                  }
                }
              }
            }
          },
          "403": {
            "description": "Access denied",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                },
                "example": {
                  "error": {
                    "code": 403,
                    "message": "Access denied for this model",
                    "type": "permission_error",
                    "param": "model"
                  }
                }
              }
            }
          },
          "404": {
            "description": "Resource not found",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                },
                "example": {
                  "error": {
                    "code": 404,
                    "message": "Specified model not found",
                    "type": "not_found_error",
                    "param": "model",
                    "fallback_suggestion": "doubao-seed-2.0-pro"
                  }
                }
              }
            }
          },
          "413": {
            "description": "Request body too large",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                },
                "example": {
                  "error": {
                    "code": 413,
                    "message": "Image file too large",
                    "type": "request_too_large_error",
                    "param": "content",
                    "fallback_suggestion": "compress image to under 10MB"
                  }
                }
              }
            }
          },
          "429": {
            "description": "Rate limit exceeded",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                },
                "example": {
                  "error": {
                    "code": 429,
                    "message": "Rate limit exceeded",
                    "type": "rate_limit_error",
                    "fallback_suggestion": "retry after 60 seconds"
                  }
                }
              }
            }
          },
          "500": {
            "description": "Internal server error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                },
                "example": {
                  "error": {
                    "code": 500,
                    "message": "Internal server error",
                    "type": "internal_server_error",
                    "fallback_suggestion": "try again later"
                  }
                }
              }
            }
          },
          "502": {
            "description": "Upstream service error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                },
                "example": {
                  "error": {
                    "code": 502,
                    "message": "Upstream AI service unavailable",
                    "type": "upstream_error",
                    "fallback_suggestion": "try different model"
                  }
                }
              }
            }
          },
          "503": {
            "description": "Service temporarily unavailable",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                },
                "example": {
                  "error": {
                    "code": 503,
                    "message": "Service temporarily unavailable",
                    "type": "service_unavailable_error",
                    "fallback_suggestion": "retry after 30 seconds"
                  }
                }
              }
            }
          }
        }
      }
    }
  },
  "components": {
    "schemas": {
      "ChatCompletionRequest": {
        "type": "object",
        "required": [
          "model",
          "messages"
        ],
        "properties": {
          "model": {
            "type": "string",
            "description": "Chat model name\n\n- `doubao-seed-2.0-pro`: Flagship, strongest overall capability, ideal for complex reasoning and high-quality generation\n- `doubao-seed-2.0-lite`: Lightweight, faster speed, cost-effective\n- `doubao-seed-2.0-mini`: Ultra-fast, quickest response, suitable for simple tasks\n- `doubao-seed-2.0-code`: Code-specialized, optimized for code generation and understanding",
            "enum": [
              "doubao-seed-2.0-pro",
              "doubao-seed-2.0-lite",
              "doubao-seed-2.0-mini",
              "doubao-seed-2.0-code"
            ],
            "default": "doubao-seed-2.0-pro",
            "example": "doubao-seed-2.0-pro"
          },
          "messages": {
            "type": "array",
            "description": "List of conversation messages, supports multi-turn conversation and multimodal input (text, image, video)",
            "items": {
              "$ref": "#/components/schemas/Message"
            },
            "minItems": 1
          },
          "thinking": {
            "type": "object",
            "description": "Control whether the model enables deep thinking mode\n\nDifferent models may vary in support and default values",
            "properties": {
              "type": {
                "type": "string",
                "description": "Thinking mode\n\n- `enabled`: Enable thinking mode, model must think before answering\n- `disabled`: Disable thinking mode, model answers directly without thinking\n- `auto`: Auto thinking mode, model decides whether to think based on the question",
                "enum": [
                  "enabled",
                  "disabled",
                  "auto"
                ],
                "example": "enabled"
              }
            },
            "required": [
              "type"
            ]
          },
          "stream": {
            "type": "boolean",
            "description": "Whether to stream the response content\n\n- `false`: Model generates all content before returning the result at once\n- `true`: Returns model-generated content incrementally via SSE protocol, ending with a `data: [DONE]` message. When stream is true, you can set the stream_options field to get token usage statistics",
            "default": false,
            "example": false
          },
          "stream_options": {
            "type": "object",
            "nullable": true,
            "description": "Options for streaming responses. Can be set when stream is true",
            "properties": {
              "include_usage": {
                "type": "boolean",
                "nullable": true,
                "description": "Whether to output token usage information before streaming output ends\n\n- `true`: Before the `data: [DONE]` message, an additional chunk will be returned with the usage field containing total token usage for the entire request, and an empty choices array\n- `false`: No chunk is returned with token usage information before output ends",
                "default": false,
                "example": true
              },
              "chunk_include_usage": {
                "type": "boolean",
                "nullable": true,
                "description": "Whether each chunk in streaming output includes cumulative token usage information up to that point\n\n- `true`: The usage field in each returned chunk contains cumulative token usage from the start of the request to the current chunk\n- `false`: Token usage information is not included in each chunk",
                "default": false
              }
            }
          },
          "max_tokens": {
            "type": "integer",
            "nullable": true,
            "description": "Maximum length of model response (in tokens)\n\n**Note**:\n- Model response does not include chain-of-thought content (model response = model output - model chain-of-thought)\n- Total output token length is also limited by the model's context length\n- Cannot be set simultaneously with max_completion_tokens",
            "default": 4096,
            "example": 4096
          },
          "max_completion_tokens": {
            "type": "integer",
            "nullable": true,
            "description": "Controls the maximum output length of the model, including both response and chain-of-thought content (in tokens)\n\n**Note**:\n- Value range: [0, 65536]\n- When configured, the default value of max_tokens becomes ineffective; the model outputs content (response and chain-of-thought) as needed until reaching this value\n- Cannot be set simultaneously with max_tokens\n- Recommended when deep thinking mode is enabled",
            "minimum": 0,
            "maximum": 65536,
            "example": 16384
          },
          "temperature": {
            "type": "number",
            "nullable": true,
            "description": "Sampling temperature, controls output randomness\n\n**Note**:\n- Value range: [0, 2]\n- Lower values (e.g., 0.2): More deterministic, more focused output\n- Higher values (e.g., 0.8): More random, more creative output\n- A value of 0 means the model only considers the token with the highest log probability\n- It is recommended to adjust only temperature or top_p, not both",
            "minimum": 0,
            "maximum": 2,
            "default": 1,
            "example": 0.7
          },
          "top_p": {
            "type": "number",
            "nullable": true,
            "description": "Nucleus sampling probability threshold\n\n**Note**:\n- Value range: [0, 1]\n- The model considers tokens within the top_p probability mass\n- 0.1 means only considering the top 10% of tokens by probability mass\n- Higher values produce more random output, lower values produce more deterministic output\n- It is recommended to adjust only temperature or top_p, not both",
            "minimum": 0,
            "maximum": 1,
            "default": 0.7,
            "example": 0.9
          },
          "stop": {
            "description": "The model will stop generating when it encounters the string(s) specified in the stop field. The stop string itself will not be included in the output. Up to 4 strings are supported\n\n**Note**: Deep thinking models do not support this field",
            "nullable": true,
            "oneOf": [
              {
                "type": "string"
              },
              {
                "type": "array",
                "items": {
                  "type": "string"
                },
                "maxItems": 4
              }
            ],
            "example": ["hello", "weather"]
          },
          "reasoning_effort": {
            "type": "string",
            "nullable": true,
            "description": "Limits the amount of thinking effort, reducing thinking depth can improve speed and consume fewer tokens\n\n- `minimal`: Disable thinking, answer directly\n- `low`: Lightweight thinking, prioritizes quick response\n- `medium`: Balanced mode, balances speed and depth\n- `high`: Deep analysis, handles complex problems",
            "enum": [
              "minimal",
              "low",
              "medium",
              "high"
            ],
            "default": "medium",
            "example": "medium"
          },
          "response_format": {
            "type": "object",
            "description": "Specify the model response format\n\nSupports three formats: text (default), json_object, json_schema",
            "properties": {
              "type": {
                "type": "string",
                "description": "Response format type\n\n- `text`: Default text format\n- `json_object`: Model response content is organized as a JSON object structure\n- `json_schema`: Model response content follows the JSON structure defined in the schema field",
                "enum": [
                  "text",
                  "json_object",
                  "json_schema"
                ],
                "default": "text",
                "example": "text"
              },
              "json_schema": {
                "type": "object",
                "description": "JSON structure definition (required when type is json_schema)",
                "properties": {
                  "name": {
                    "type": "string",
                    "description": "User-defined JSON structure name"
                  },
                  "description": {
                    "type": "string",
                    "nullable": true,
                    "description": "Description of the response purpose; the model will use this to determine how to respond in the specified format"
                  },
                  "schema": {
                    "type": "object",
                    "description": "JSON format definition for the response, described as a JSON Schema object"
                  },
                  "strict": {
                    "type": "boolean",
                    "nullable": true,
                    "description": "Whether to enable strict adherence mode\n\n- `true`: The model will always strictly follow the format defined in the schema field\n- `false`: The model will try its best to follow the structure defined in the schema field",
                    "default": false
                  }
                },
                "required": [
                  "name",
                  "schema"
                ]
              }
            },
            "required": [
              "type"
            ]
          },
          "frequency_penalty": {
            "type": "number",
            "nullable": true,
            "description": "Frequency penalty coefficient\n\n**Note**:\n- Value range: [-2.0, 2.0]\n- Positive values penalize new tokens based on their frequency in the text so far, reducing the likelihood of the model repeating the same content verbatim",
            "minimum": -2,
            "maximum": 2,
            "default": 0,
            "example": 0
          },
          "presence_penalty": {
            "type": "number",
            "nullable": true,
            "description": "Presence penalty coefficient\n\n**Note**:\n- Value range: [-2.0, 2.0]\n- Positive values penalize new tokens based on whether they have appeared in the text so far, increasing the likelihood of the model talking about new topics",
            "minimum": -2,
            "maximum": 2,
            "default": 0,
            "example": 0
          },
          "logprobs": {
            "type": "boolean",
            "nullable": true,
            "description": "Whether to return log probabilities of output tokens\n\n- `false`: Do not return log probability information\n- `true`: Return log probabilities for each output token in the message content\n\n**Note**: Deep thinking models do not support this field",
            "default": false
          },
          "top_logprobs": {
            "type": "integer",
            "nullable": true,
            "description": "Specify the number of most likely tokens to return at each output token position, each with an associated log probability\n\n- Value range: [0, 20]\n- Can only be set when logprobs is true\n\n**Note**: Deep thinking models do not support this field",
            "minimum": 0,
            "maximum": 20,
            "default": 0
          },
          "logit_bias": {
            "type": "object",
            "nullable": true,
            "description": "Adjust the probability of specified tokens appearing in the model output\n\n**Note**:\n- Accepts a map where keys are token IDs from the vocabulary and values are bias values\n- Bias value range: [-100, 100]\n- -1 reduces the likelihood of selection, 1 increases the likelihood of selection\n- -100 completely prohibits selection of the token, 100 causes only that token to be selectable\n\n**Note**: Deep thinking models do not support this field",
            "additionalProperties": {
              "type": "integer",
              "minimum": -100,
              "maximum": 100
            }
          },
          "tools": {
            "type": "array",
            "nullable": true,
            "description": "List of tools to be called; the model response may contain tool call requests",
            "items": {
              "$ref": "#/components/schemas/Tool"
            }
          },
          "parallel_tool_calls": {
            "type": "boolean",
            "description": "Whether the model response is allowed to contain multiple tool calls for this request\n\n- `true`: Allow returning multiple tool calls\n- `false`: The number of tool calls returned is <= 1",
            "default": true
          },
          "tool_choice": {
            "description": "Whether the model response should contain tool calls for this request\n\n**String mode**:\n- `none`: Model response does not contain tool calls\n- `required`: Model response must contain tool calls\n- `auto`: Model decides whether to include tool calls (default when tools are provided)\n\n**Object mode**: Specify the scope of tools to be called",
            "oneOf": [
              {
                "type": "string",
                "enum": [
                  "none",
                  "auto",
                  "required"
                ]
              },
              {
                "$ref": "#/components/schemas/ToolChoiceObject"
              }
            ]
          }
        }
      },
      "Message": {
        "type": "object",
        "required": [
          "role",
          "content"
        ],
        "properties": {
          "role": {
            "type": "string",
            "description": "Message role\n\n- `user`: User message\n- `assistant`: AI assistant message (for multi-turn conversations)\n- `system`: System prompt (define AI role and behavior)\n- `tool`: Tool response message (for tool calling scenarios)",
            "enum": [
              "user",
              "assistant",
              "system",
              "tool"
            ],
            "example": "user"
          },
          "content": {
            "type": "array",
            "description": "Message content. Supports two formats:\n\n**1. Plain text string**: You can pass a string directly, e.g., `\"content\": \"Please introduce yourself\"`\n\n**2. Object array** (supports multimodal input including text, image, video): See the structure below",
            "items": {
              "$ref": "#/components/schemas/ContentPart"
            }
          },
          "reasoning_content": {
            "type": "string",
            "description": "Chain-of-thought content in model messages (assistant role only)\n\nOnly used when passing historical chain-of-thought content in multi-turn conversations"
          },
          "tool_calls": {
            "type": "array",
            "description": "Tool call part of model messages (assistant role only)",
            "items": {
              "$ref": "#/components/schemas/ToolCall"
            }
          },
          "tool_call_id": {
            "type": "string",
            "description": "Tool call request ID generated by the model (required for tool role only)\n\nUsed to associate tool return results with model requests, avoiding confusion in multi-tool call scenarios"
          }
        }
      },
      "ContentPart": {
        "oneOf": [
          {
            "$ref": "#/components/schemas/TextContent"
          },
          {
            "$ref": "#/components/schemas/ImageContent"
          },
          {
            "$ref": "#/components/schemas/VideoContent"
          }
        ]
      },
      "TextContent": {
        "title": "Text Content",
        "type": "object",
        "required": [
          "type",
          "text"
        ],
        "properties": {
          "type": {
            "type": "string",
            "enum": [
              "text"
            ],
            "description": "Content type"
          },
          "text": {
            "type": "string",
            "description": "Text content",
            "example": "Please describe this image in detail"
          }
        }
      },
      "ImageContent": {
        "title": "Image Content",
        "type": "object",
        "required": [
          "type",
          "image_url"
        ],
        "properties": {
          "type": {
            "type": "string",
            "enum": [
              "image_url"
            ],
            "description": "Content type"
          },
          "image_url": {
            "type": "object",
            "required": [
              "url"
            ],
            "properties": {
              "url": {
                "type": "string",
                "format": "uri",
                "description": "Image URL or Base64 encoding\n\n**Supported formats**:\n- Image link (publicly accessible)\n- Base64 encoded image",
                "example": "https://example.com/image.png"
              },
              "detail": {
                "type": "string",
                "nullable": true,
                "description": "Image understanding detail level\n\n- `low`: Low detail\n- `high`: High detail\n- `xhigh`: Ultra-high detail",
                "enum": [
                  "low",
                  "high",
                  "xhigh"
                ]
              }
            }
          }
        }
      },
      "VideoContent": {
        "title": "Video Content",
        "type": "object",
        "required": [
          "type",
          "video_url"
        ],
        "properties": {
          "type": {
            "type": "string",
            "enum": [
              "video_url"
            ],
            "description": "Content type"
          },
          "video_url": {
            "type": "object",
            "required": [
              "url"
            ],
            "properties": {
              "url": {
                "type": "string",
                "format": "uri",
                "description": "Video URL or Base64 encoding\n\n**Supported formats**:\n- Video link (publicly accessible)\n- Base64 encoded video\n\n**Note**: Audio content within the video is not supported for understanding",
                "example": "https://example.com/video.mp4"
              },
              "fps": {
                "type": "number",
                "nullable": true,
                "description": "Frame extraction rate\n\n- Value range: [0.2, 5]\n- Higher values make the model more sensitive to visual changes in the video\n- Lower values make the model less sensitive to visual changes, but consume fewer tokens and are faster",
                "minimum": 0.2,
                "maximum": 5,
                "default": 1,
                "example": 1
              }
            }
          }
        }
      },
      "Tool": {
        "type": "object",
        "required": [
          "type",
          "function"
        ],
        "properties": {
          "type": {
            "type": "string",
            "description": "Tool type, currently only supports function",
            "enum": [
              "function"
            ]
          },
          "function": {
            "type": "object",
            "required": [
              "name"
            ],
            "description": "Function definition",
            "properties": {
              "name": {
                "type": "string",
                "description": "Name of the function to call"
              },
              "description": {
                "type": "string",
                "description": "Description of the function; the model will use this to determine whether to call this tool"
              },
              "parameters": {
                "type": "object",
                "description": "Function request parameters, described in JSON Schema format\n\n**Note**:\n- All field names are case-sensitive\n- parameters must be a valid JSON Schema object\n- It is recommended to use English field names and put Chinese descriptions in the description field"
              }
            }
          }
        }
      },
      "ToolChoiceObject": {
        "type": "object",
        "required": [
          "type",
          "function"
        ],
        "description": "Specify the scope of tools to be called",
        "properties": {
          "type": {
            "type": "string",
            "description": "Call type",
            "enum": [
              "function"
            ]
          },
          "function": {
            "type": "object",
            "required": [
              "name"
            ],
            "properties": {
              "name": {
                "type": "string",
                "description": "Name of the tool to be called"
              }
            }
          }
        }
      },
      "ToolCall": {
        "type": "object",
        "properties": {
          "id": {
            "type": "string",
            "description": "ID of the called tool, generated by the model"
          },
          "type": {
            "type": "string",
            "description": "Tool type, currently only supports function",
            "enum": [
              "function"
            ]
          },
          "function": {
            "type": "object",
            "properties": {
              "name": {
                "type": "string",
                "description": "Name of the function to call"
              },
              "arguments": {
                "type": "string",
                "description": "Arguments for the function to call, in JSON format\n\n**Note**: The model does not always generate valid JSON and may hallucinate parameters that are not defined. It is recommended to validate parameters before calling the function"
              }
            }
          }
        }
      },
      "ChatCompletionResponse": {
        "type": "object",
        "properties": {
          "id": {
            "type": "string",
            "description": "Unique identifier for this request",
            "example": "0217714854126607f5a9cf8ed5b018c76e4ad3dc2810db57ffb50"
          },
          "model": {
            "type": "string",
            "description": "Actual model name and version used for this request",
            "example": "doubao-seed-2-0-pro-260215"
          },
          "object": {
            "type": "string",
            "enum": [
              "chat.completion"
            ],
            "description": "Response type, always chat.completion",
            "example": "chat.completion"
          },
          "service_tier": {
            "type": "string",
            "description": "Service tier for this request\n\n- `default`: Default service tier\n- `scale`: Used reserved capacity quota",
            "enum": [
              "default",
              "scale"
            ],
            "example": "default"
          },
          "created": {
            "type": "integer",
            "description": "Unix timestamp (in seconds) of when this request was created",
            "example": 1771485416
          },
          "choices": {
            "type": "array",
            "description": "Model output content for this request",
            "items": {
              "$ref": "#/components/schemas/Choice"
            }
          },
          "usage": {
            "$ref": "#/components/schemas/Usage"
          }
        }
      },
      "Choice": {
        "type": "object",
        "properties": {
          "index": {
            "type": "integer",
            "description": "Index of the current element in the choices list",
            "example": 0
          },
          "message": {
            "$ref": "#/components/schemas/AssistantMessage"
          },
          "finish_reason": {
            "type": "string",
            "description": "Reason why the model stopped generating tokens\n\n- `stop`: Model output ended naturally, or was truncated due to hitting a string specified in the stop parameter\n- `length`: Model output was truncated due to reaching max_tokens / max_completion_tokens / context length limit\n- `content_filter`: Model output was blocked by content moderation\n- `tool_calls`: Model called a tool",
            "enum": [
              "stop",
              "length",
              "content_filter",
              "tool_calls"
            ],
            "example": "stop"
          },
          "logprobs": {
            "type": "object",
            "nullable": true,
            "description": "Log probability information for the current content",
            "properties": {
              "content": {
                "type": "array",
                "nullable": true,
                "description": "Token log probability information for each content element",
                "items": {
                  "$ref": "#/components/schemas/LogprobContent"
                }
              }
            }
          },
          "moderation_hit_type": {
            "type": "string",
            "nullable": true,
            "description": "When model output contains sensitive content, returns the matched risk classification label\n\n- `severe_violation`: Model output involves severe violation\n- `violence`: Model output involves violent behavior",
            "enum": [
              "severe_violation",
              "violence"
            ]
          }
        }
      },
      "AssistantMessage": {
        "type": "object",
        "properties": {
          "role": {
            "type": "string",
            "description": "Role of the content output, always assistant",
            "enum": [
              "assistant"
            ],
            "example": "assistant"
          },
          "content": {
            "type": "string",
            "description": "Message content generated by the model",
            "example": "Hello! Doubao Seed 2.0 is a next-generation large language model from ByteDance, featuring enhanced reasoning, multimodal understanding, and deep thinking capabilities."
          },
          "reasoning_content": {
            "type": "string",
            "nullable": true,
            "description": "Chain-of-thought content from the model's problem-solving process\n\nOnly returned when deep thinking mode is enabled"
          },
          "tool_calls": {
            "type": "array",
            "nullable": true,
            "description": "Tool calls generated by the model",
            "items": {
              "$ref": "#/components/schemas/ToolCall"
            }
          }
        }
      },
      "LogprobContent": {
        "type": "object",
        "properties": {
          "token": {
            "type": "string",
            "description": "Current token"
          },
          "bytes": {
            "type": "array",
            "nullable": true,
            "description": "UTF-8 value of the current token, as a list of integers",
            "items": {
              "type": "integer"
            }
          },
          "logprob": {
            "type": "number",
            "description": "Log probability of the current token"
          },
          "top_logprobs": {
            "type": "array",
            "description": "List of the most likely tokens at the current token position and their log probabilities",
            "items": {
              "type": "object",
              "properties": {
                "token": {
                  "type": "string",
                  "description": "Current token"
                },
                "bytes": {
                  "type": "array",
                  "nullable": true,
                  "description": "UTF-8 value of the current token",
                  "items": {
                    "type": "integer"
                  }
                },
                "logprob": {
                  "type": "number",
                  "description": "Log probability of the current token"
                }
              }
            }
          }
        }
      },
      "Usage": {
        "type": "object",
        "description": "Token usage for this request",
        "properties": {
          "total_tokens": {
            "type": "integer",
            "description": "Total number of tokens consumed by this request (input + output)",
            "example": 271
          },
          "prompt_tokens": {
            "type": "integer",
            "description": "Number of tokens in the content input to the model",
            "example": 15
          },
          "prompt_tokens_details": {
            "type": "object",
            "description": "Details of input token count",
            "properties": {
              "cached_tokens": {
                "type": "integer",
                "description": "Token usage for cached input content",
                "example": 0
              }
            }
          },
          "completion_tokens": {
            "type": "integer",
            "description": "Tokens consumed by model output content",
            "example": 256
          },
          "completion_tokens_details": {
            "type": "object",
            "description": "Details of output token consumption",
            "properties": {
              "reasoning_tokens": {
                "type": "integer",
                "description": "Number of tokens consumed by chain-of-thought output",
                "example": 0
              }
            }
          }
        }
      },
      "ErrorResponse": {
        "type": "object",
        "properties": {
          "error": {
            "type": "object",
            "properties": {
              "code": {
                "type": "integer",
                "description": "HTTP status error code"
              },
              "message": {
                "type": "string",
                "description": "Error description message"
              },
              "type": {
                "type": "string",
                "description": "Error type"
              },
              "param": {
                "type": "string",
                "description": "Related parameter name"
              },
              "fallback_suggestion": {
                "type": "string",
                "description": "Suggestion on error"
              }
            }
          }
        }
      }
    },
    "securitySchemes": {
      "bearerAuth": {
        "type": "http",
        "scheme": "bearer",
        "description": "##All APIs require Bearer Token authentication##\n\n**Get API Key:**\n\nVisit the [API Key Management Page](https://evolink.ai/dashboard/keys) to get your API Key\n\n**Add to request headers:**\n```\nAuthorization: Bearer YOUR_API_KEY\n```"
      }
    }
  },
  "tags": [
    {
      "name": "Chat Completion",
      "description": "AI chat completion related APIs"
    }
  ]
}