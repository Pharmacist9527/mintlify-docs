{
  "openapi": "3.1.0",
  "info": {
    "title": "Doubao Seed 2.0 Vollstaendige API-Referenz",
    "description": "Vollstaendige API-Referenz fuer die Doubao Seed 2.0 Chat-Schnittstelle, einschliesslich aller Parameter und erweiterten Funktionen",
    "license": {
      "name": "MIT"
    },
    "version": "1.0.0"
  },
  "servers": [
    {
      "url": "https://api.evolink.ai",
      "description": "Produktionsumgebung"
    }
  ],
  "security": [
    {
      "bearerAuth": []
    }
  ],
  "paths": {
    "/v1/chat/completions": {
      "post": {
        "summary": "Doubao Seed 2.0 Chat-Schnittstelle",
        "description": "- Doubao Seed 2.0 Modelle im OpenAI-SDK-Format aufrufen\n- Synchroner Verarbeitungsmodus, Echtzeit-Antwort\n- **Text-Chat**: Einzel- oder Mehrrundenkonversation mit Kontext\n- **System-Prompts**: KI-Rolle und -Verhalten anpassen\n- **Multimodale Eingabe**: Unterstuetzung fuer Text + Bild + Video gemischte Eingabe\n- **Tiefes Denken**: Unterstuetzung fuer Chain-of-Thought-Modus fuer tiefes Reasoning\n- **Tool Calling**: Function-Calling-Unterstuetzung\n- **Strukturierte Ausgabe**: Unterstuetzung fuer JSON Object / JSON Schema Formatausgabe\n- Schnelleinstieg? Siehe [Schnellstart-Dokumentation](./doubao-seed-2.0-quickstart)",
        "operationId": "createChatCompletionDoubaoSeed20",
        "tags": [
          "Chat-Generierung"
        ],
        "requestBody": {
          "required": true,
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/ChatCompletionRequest"
              },
              "examples": {
                "simple_text": {
                  "summary": "Einzelrunden-Text-Chat",
                  "value": {
                    "model": "doubao-seed-2.0-pro",
                    "messages": [
                      {
                        "role": "user",
                        "content": "Bitte stellen Sie sich vor"
                      }
                    ]
                  }
                },
                "multi_turn": {
                  "summary": "Mehrrunden-Konversation (Kontextverstaendnis)",
                  "value": {
                    "model": "doubao-seed-2.0-pro",
                    "messages": [
                      {
                        "role": "user",
                        "content": "Was ist Python?"
                      },
                      {
                        "role": "assistant",
                        "content": "Python ist eine hoehere Programmiersprache..."
                      },
                      {
                        "role": "user",
                        "content": "Was sind die Vorteile?"
                      }
                    ]
                  }
                },
                "system_prompt": {
                  "summary": "System-Prompt verwenden",
                  "value": {
                    "model": "doubao-seed-2.0-pro",
                    "messages": [
                      {
                        "role": "system",
                        "content": "Sie sind ein professioneller Python-Programmierassistent, der Fragen praegnant beantwortet."
                      },
                      {
                        "role": "user",
                        "content": "Wie liest man eine Datei?"
                      }
                    ]
                  }
                },
                "vision": {
                  "summary": "Multimodale Eingabe (Text + Bild)",
                  "value": {
                    "model": "doubao-seed-2.0-pro",
                    "messages": [
                      {
                        "role": "user",
                        "content": [
                          {
                            "type": "text",
                            "text": "Bitte beschreiben Sie die Szene und die Hauptelemente in diesem Bild ausfuehrlich."
                          },
                          {
                            "type": "image_url",
                            "image_url": {
                              "url": "https://example.com/image.png"
                            }
                          }
                        ]
                      }
                    ]
                  }
                },
                "thinking_mode": {
                  "summary": "Tiefes-Denken-Modus aktivieren",
                  "value": {
                    "model": "doubao-seed-2.0-pro",
                    "messages": [
                      {
                        "role": "user",
                        "content": "Beweisen Sie, dass die Quadratwurzel von 2 irrational ist"
                      }
                    ],
                    "thinking": {
                      "type": "enabled"
                    },
                    "max_completion_tokens": 16384
                  }
                },
                "code_generation": {
                  "summary": "Code-Spezialmodell verwenden",
                  "value": {
                    "model": "doubao-seed-2.0-code",
                    "messages": [
                      {
                        "role": "system",
                        "content": "Sie sind ein fortgeschrittener Programmierassistent."
                      },
                      {
                        "role": "user",
                        "content": "Implementieren Sie einen Quicksort-Algorithmus in Python"
                      }
                    ]
                  }
                }
              }
            }
          }
        },
        "responses": {
          "200": {
            "description": "Chat-Generierung erfolgreich",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ChatCompletionResponse"
                }
              }
            }
          },
          "400": {
            "description": "Ungueltige Anfrageparameter",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                },
                "example": {
                  "error": {
                    "code": 400,
                    "message": "Invalid request parameters",
                    "type": "invalid_request_error"
                  }
                }
              }
            }
          },
          "401": {
            "description": "Nicht authentifiziert, Token ungueltig oder abgelaufen",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                },
                "example": {
                  "error": {
                    "code": 401,
                    "message": "Invalid or expired token",
                    "type": "authentication_error"
                  }
                }
              }
            }
          },
          "402": {
            "description": "Unzureichendes Kontingent, Aufladung erforderlich",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                },
                "example": {
                  "error": {
                    "code": 402,
                    "message": "Insufficient quota",
                    "type": "insufficient_quota_error",
                    "fallback_suggestion": "https://evolink.ai/dashboard/billing"
                  }
                }
              }
            }
          },
          "403": {
            "description": "Kein Zugriff erlaubt",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                },
                "example": {
                  "error": {
                    "code": 403,
                    "message": "Access denied for this model",
                    "type": "permission_error",
                    "param": "model"
                  }
                }
              }
            }
          },
          "404": {
            "description": "Ressource nicht gefunden",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                },
                "example": {
                  "error": {
                    "code": 404,
                    "message": "Specified model not found",
                    "type": "not_found_error",
                    "param": "model",
                    "fallback_suggestion": "doubao-seed-2.0-pro"
                  }
                }
              }
            }
          },
          "413": {
            "description": "Anfrage zu gross",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                },
                "example": {
                  "error": {
                    "code": 413,
                    "message": "Image file too large",
                    "type": "request_too_large_error",
                    "param": "content",
                    "fallback_suggestion": "compress image to under 10MB"
                  }
                }
              }
            }
          },
          "429": {
            "description": "Anfragelimit ueberschritten",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                },
                "example": {
                  "error": {
                    "code": 429,
                    "message": "Rate limit exceeded",
                    "type": "rate_limit_error",
                    "fallback_suggestion": "retry after 60 seconds"
                  }
                }
              }
            }
          },
          "500": {
            "description": "Interner Serverfehler",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                },
                "example": {
                  "error": {
                    "code": 500,
                    "message": "Internal server error",
                    "type": "internal_server_error",
                    "fallback_suggestion": "try again later"
                  }
                }
              }
            }
          },
          "502": {
            "description": "Upstream-Dienstfehler",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                },
                "example": {
                  "error": {
                    "code": 502,
                    "message": "Upstream AI service unavailable",
                    "type": "upstream_error",
                    "fallback_suggestion": "try different model"
                  }
                }
              }
            }
          },
          "503": {
            "description": "Dienst voruebergehend nicht verfuegbar",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                },
                "example": {
                  "error": {
                    "code": 503,
                    "message": "Service temporarily unavailable",
                    "type": "service_unavailable_error",
                    "fallback_suggestion": "retry after 30 seconds"
                  }
                }
              }
            }
          }
        }
      }
    }
  },
  "components": {
    "schemas": {
      "ChatCompletionRequest": {
        "type": "object",
        "required": ["model", "messages"],
        "properties": {
          "model": {
            "type": "string",
            "description": "Chat-Modellname\n\n- `doubao-seed-2.0-pro`: Flaggschiff-Version, staerkste Gesamtleistung, geeignet fuer komplexes Reasoning und hochwertige Generierung\n- `doubao-seed-2.0-lite`: Leichtversion, schneller, gutes Preis-Leistungs-Verhaeltnis\n- `doubao-seed-2.0-mini`: Ultraschnelle Version, schnellste Antwort, geeignet fuer einfache Aufgaben\n- `doubao-seed-2.0-code`: Code-Spezialversion, optimiert fuer Codegenerierung und -verstaendnis",
            "enum": ["doubao-seed-2.0-pro", "doubao-seed-2.0-lite", "doubao-seed-2.0-mini", "doubao-seed-2.0-code"],
            "default": "doubao-seed-2.0-pro",
            "example": "doubao-seed-2.0-pro"
          },
          "messages": {
            "type": "array",
            "description": "Chat-Nachrichtenliste, unterstuetzt Mehrrunden-Konversation und multimodale Eingabe (Text, Bild, Video)",
            "items": {
              "$ref": "#/components/schemas/Message"
            },
            "minItems": 1
          },
          "thinking": {
            "type": "object",
            "description": "Steuert, ob das Modell den Tiefes-Denken-Modus aktiviert\n\nOb und welcher Standardwert gilt, haengt vom jeweiligen Modell ab",
            "properties": {
              "type": {
                "type": "string",
                "description": "Denkmodus\n\n- `enabled`: Denkmodus aktiviert, Modell denkt zuerst und antwortet dann\n- `disabled`: Denkmodus deaktiviert, Modell antwortet direkt ohne zu denken\n- `auto`: Automatischer Denkmodus, Modell entscheidet selbst ob Denken noetig ist",
                "enum": ["enabled", "disabled", "auto"],
                "example": "enabled"
              }
            },
            "required": ["type"]
          },
          "stream": {
            "type": "boolean",
            "description": "Ob die Antwort als Stream zurueckgegeben wird\n\n- `false`: Modell generiert den gesamten Inhalt und gibt das Ergebnis auf einmal zurueck\n- `true`: Gibt den Modellinhalt blockweise per SSE-Protokoll zurueck, endet mit einer `data: [DONE]` Nachricht. Wenn stream true ist, kann stream_options fuer Token-Verbrauchsstatistiken gesetzt werden",
            "default": false,
            "example": false
          },
          "stream_options": {
            "type": "object",
            "nullable": true,
            "description": "Optionen fuer Streaming-Antworten. Kann gesetzt werden, wenn stream true ist",
            "properties": {
              "include_usage": {
                "type": "boolean",
                "nullable": true,
                "description": "Ob bei Streaming-Ausgabe vor dem Ende die Token-Verbrauchsinformationen ausgegeben werden\n\n- `true`: Vor der `data: [DONE]` Nachricht wird ein zusaetzlicher Chunk zurueckgegeben, dessen usage-Feld den Token-Verbrauch der gesamten Anfrage enthaelt, choices-Feld ist ein leeres Array\n- `false`: Vor dem Ende wird kein Chunk mit Token-Verbrauchsinformationen zurueckgegeben",
                "default": false,
                "example": true
              },
              "chunk_include_usage": {
                "type": "boolean",
                "nullable": true,
                "description": "Ob bei Streaming-Ausgabe jeder Chunk die kumulierten Token-Verbrauchsinformationen bis zu diesem Zeitpunkt enthaelt\n\n- `true`: Im usage-Feld wird der kumulative Token-Verbrauch bis zu diesem Chunk ausgegeben\n- `false`: Nicht in jedem Chunk Token-Verbrauchsinformationen zurueckgeben",
                "default": false
              }
            }
          },
          "max_tokens": {
            "type": "integer",
            "nullable": true,
            "description": "Maximale Antwortlaenge des Modells (in Token)\n\n**Hinweis**:\n- Modellantwort enthaelt keinen Chain-of-Thought-Inhalt (Modellantwort = Modellausgabe - Modell-Chain-of-Thought)\n- Die Gesamtlaenge der Ausgabe-Token wird auch durch die Kontextlaenge des Modells begrenzt\n- Kann nicht gleichzeitig mit max_completion_tokens gesetzt werden",
            "default": 4096,
            "example": 4096
          },
          "max_completion_tokens": {
            "type": "integer",
            "nullable": true,
            "description": "Steuert die maximale Ausgabelaenge des Modells, einschliesslich Antwort- und Chain-of-Thought-Inhalt (in Token)\n\n**Hinweis**:\n- Wertebereich: [0, 65536]\n- Nach Konfiguration wird der Standardwert von max_tokens ungueltig, Modell gibt Inhalt (Antwort und Chain-of-Thought) nach Bedarf aus, bis dieser Wert erreicht ist\n- Kann nicht gleichzeitig mit max_tokens gesetzt werden\n- Empfohlen bei aktiviertem Tiefes-Denken-Modus",
            "minimum": 0,
            "maximum": 65536,
            "example": 16384
          },
          "temperature": {
            "type": "number",
            "nullable": true,
            "description": "Sampling-Temperatur, steuert die Zufaelligkeit der Ausgabe\n\n**Hinweis**:\n- Wertebereich: [0, 2]\n- Niedrigere Werte (z.B. 0.2): Deterministischere, fokussiertere Ausgabe\n- Hoehere Werte (z.B. 0.8): Zufaelligere, kreativere Ausgabe\n- Bei Wert 0 beruecksichtigt das Modell nur den Token mit der hoechsten Log-Wahrscheinlichkeit\n- Es wird empfohlen, nur temperature oder top_p anzupassen, nicht beides",
            "minimum": 0,
            "maximum": 2,
            "default": 1,
            "example": 0.7
          },
          "top_p": {
            "type": "number",
            "nullable": true,
            "description": "Nucleus-Sampling-Wahrscheinlichkeitsschwelle\n\n**Hinweis**:\n- Wertebereich: [0, 1]\n- Das Modell beruecksichtigt Token-Ergebnisse innerhalb der top_p Wahrscheinlichkeitsmasse\n- 0.1 bedeutet, dass nur die Top 10% der wahrscheinlichsten Token beruecksichtigt werden\n- Hoehere Werte erzeugen mehr Zufaelligkeit, niedrigere Werte mehr Determinismus\n- Es wird empfohlen, nur temperature oder top_p anzupassen, nicht beides",
            "minimum": 0,
            "maximum": 1,
            "default": 0.7,
            "example": 0.9
          },
          "stop": {
            "description": "Das Modell stoppt die Generierung, wenn es auf die im stop-Feld angegebenen Zeichenketten trifft. Das Wort selbst wird nicht ausgegeben. Maximal 4 Zeichenketten\n\n**Hinweis**: Tiefes-Denken-Modelle unterstuetzen dieses Feld nicht",
            "nullable": true,
            "oneOf": [
              {
                "type": "string"
              },
              {
                "type": "array",
                "items": {
                  "type": "string"
                },
                "maxItems": 4
              }
            ],
            "example": ["Hallo", "Wetter"]
          },
          "reasoning_effort": {
            "type": "string",
            "nullable": true,
            "description": "Begrenzt den Denkaufwand, weniger Denktiefe kann die Geschwindigkeit erhoehen und weniger Token verbrauchen\n\n- `minimal`: Denken deaktiviert, direkte Antwort\n- `low`: Leichtes Denken, Fokus auf schnelle Antwort\n- `medium`: Ausgewogener Modus, Balance zwischen Geschwindigkeit und Tiefe\n- `high`: Tiefenanalyse, fuer komplexe Probleme",
            "enum": ["minimal", "low", "medium", "high"],
            "default": "medium",
            "example": "medium"
          },
          "response_format": {
            "type": "object",
            "description": "Antwortformat des Modells festlegen\n\nDrei Formate unterstuetzt: text (Standard), json_object, json_schema",
            "properties": {
              "type": {
                "type": "string",
                "description": "Antwortformattyp\n\n- `text`: Standard-Textformat\n- `json_object`: Modellantwort als JSON-Objektstruktur\n- `json_schema`: Modellantwort folgt der im schema-Feld definierten JSON-Struktur",
                "enum": ["text", "json_object", "json_schema"],
                "default": "text",
                "example": "text"
              },
              "json_schema": {
                "type": "object",
                "description": "JSON-Strukturdefinition (erforderlich wenn type json_schema ist)",
                "properties": {
                  "name": {
                    "type": "string",
                    "description": "Benutzerdefinierter JSON-Strukturname"
                  },
                  "description": {
                    "type": "string",
                    "nullable": true,
                    "description": "Beschreibung des Antwortzwecks, das Modell entscheidet anhand dieser Beschreibung, wie es in diesem Format antwortet"
                  },
                  "schema": {
                    "type": "object",
                    "description": "JSON-Formatdefinition des Antwortformats, beschrieben als JSON-Schema-Objekt"
                  },
                  "strict": {
                    "type": "boolean",
                    "nullable": true,
                    "description": "Ob der strikte Befolgungsmodus aktiviert werden soll\n\n- `true`: Modell folgt immer strikt der im schema-Feld definierten Struktur\n- `false`: Modell versucht, der im schema-Feld definierten Struktur zu folgen",
                    "default": false
                  }
                },
                "required": ["name", "schema"]
              }
            },
            "required": ["type"]
          },
          "frequency_penalty": {
            "type": "number",
            "nullable": true,
            "description": "Frequenzbestrafungskoeffizient\n\n**Hinweis**:\n- Wertebereich: [-2.0, 2.0]\n- Bei positiven Werten werden neue Token basierend auf ihrer Haeufigkeit im Text bestraft, wodurch die Wahrscheinlichkeit woertlicher Wiederholungen verringert wird",
            "minimum": -2,
            "maximum": 2,
            "default": 0,
            "example": 0
          },
          "presence_penalty": {
            "type": "number",
            "nullable": true,
            "description": "Praesenzbestrafungskoeffizient\n\n**Hinweis**:\n- Wertebereich: [-2.0, 2.0]\n- Bei positiven Werten werden neue Token bestraft, wenn sie bereits im Text vorkommen, wodurch die Wahrscheinlichkeit erhoeht wird, dass das Modell neue Themen anspricht",
            "minimum": -2,
            "maximum": 2,
            "default": 0,
            "example": 0
          },
          "logprobs": {
            "type": "boolean",
            "nullable": true,
            "description": "Ob Log-Wahrscheinlichkeiten der Ausgabe-Token zurueckgegeben werden\n\n- `false`: Keine Log-Wahrscheinlichkeitsinformationen zurueckgeben\n- `true`: Log-Wahrscheinlichkeiten fuer jeden Ausgabe-Token im Nachrichteninhalt zurueckgeben\n\n**Hinweis**: Tiefes-Denken-Modelle unterstuetzen dieses Feld nicht",
            "default": false
          },
          "top_logprobs": {
            "type": "integer",
            "nullable": true,
            "description": "Anzahl der wahrscheinlichsten Token mit Log-Wahrscheinlichkeiten an jeder Token-Position\n\n- Wertebereich: [0, 20]\n- logprobs muss auf true gesetzt sein, um diesen Parameter zu verwenden",
            "minimum": 0,
            "maximum": 20
          },
          "tools": {
            "type": "array",
            "nullable": true,
            "description": "Liste der vom Modell aufrufbaren Werkzeuge. Derzeit wird nur function als Werkzeugtyp unterstuetzt",
            "items": {
              "$ref": "#/components/schemas/Tool"
            }
          },
          "tool_choice": {
            "description": "Steuert, wie das Modell Werkzeuge aufruft\n\n- `none`: Modell ruft keine Werkzeuge auf, generiert eine Nachricht\n- `auto`: Modell entscheidet selbst, ob es ein Werkzeug aufruft oder eine Nachricht generiert\n- `required`: Modell muss mindestens ein Werkzeug aufrufen\n- Objekt: Bestimmtes Werkzeug zum Aufrufen angeben",
            "nullable": true,
            "oneOf": [
              {
                "type": "string",
                "enum": ["none", "auto", "required"]
              },
              {
                "$ref": "#/components/schemas/ToolChoiceObject"
              }
            ],
            "default": "auto"
          }
        }
      },
      "Message": {
        "type": "object",
        "required": ["role", "content"],
        "properties": {
          "role": {
            "type": "string",
            "description": "Nachrichtenrolle\n\n- `system`: Systemnachricht, definiert das Verhalten der KI\n- `user`: Benutzernachricht\n- `assistant`: Assistentenantwort\n- `tool`: Werkzeugaufruf-Ergebnis",
            "enum": ["system", "user", "assistant", "tool"]
          },
          "content": {
            "description": "Nachrichteninhalt, unterstuetzt Text oder multimodale Inhaltsliste",
            "oneOf": [
              {
                "type": "string",
                "description": "Reiner Textinhalt"
              },
              {
                "type": "array",
                "description": "Multimodale Inhaltsliste (Text, Bild, Video)",
                "items": {
                  "$ref": "#/components/schemas/ContentPart"
                }
              }
            ]
          },
          "tool_calls": {
            "type": "array",
            "nullable": true,
            "description": "Vom Modell generierte Werkzeugaufrufe (nur fuer assistant-Rolle)",
            "items": {
              "$ref": "#/components/schemas/ToolCall"
            }
          },
          "tool_call_id": {
            "type": "string",
            "description": "Vom Modell generierte Werkzeugaufruf-Anfrage-ID (nur fuer tool-Rolle erforderlich)\n\nDient zur Zuordnung von Werkzeugergebnissen zu Modellanfragen, um Verwechslungen bei mehreren Werkzeugaufrufen zu vermeiden"
          }
        }
      },
      "ContentPart": {
        "oneOf": [
          {
            "$ref": "#/components/schemas/TextContent"
          },
          {
            "$ref": "#/components/schemas/ImageContent"
          },
          {
            "$ref": "#/components/schemas/VideoContent"
          }
        ]
      },
      "TextContent": {
        "title": "Textinhalt",
        "type": "object",
        "required": ["type", "text"],
        "properties": {
          "type": {
            "type": "string",
            "enum": ["text"],
            "description": "Inhaltstyp"
          },
          "text": {
            "type": "string",
            "description": "Textinhalt",
            "example": "Bitte beschreiben Sie dieses Bild ausfuehrlich"
          }
        }
      },
      "ImageContent": {
        "title": "Bildinhalt",
        "type": "object",
        "required": ["type", "image_url"],
        "properties": {
          "type": {
            "type": "string",
            "enum": ["image_url"],
            "description": "Inhaltstyp"
          },
          "image_url": {
            "type": "object",
            "required": ["url"],
            "properties": {
              "url": {
                "type": "string",
                "format": "uri",
                "description": "Bild-URL-Adresse oder Base64-Kodierung\n\n**Unterstuetzte Formate**:\n- Bildlink (oeffentlich zugaenglich)\n- Base64-Kodierung des Bildes",
                "example": "https://example.com/image.png"
              },
              "detail": {
                "type": "string",
                "nullable": true,
                "description": "Detailgrad der Bildanalyse\n\n- `low`: Niedriger Detailgrad\n- `high`: Hoher Detailgrad\n- `xhigh`: Sehr hoher Detailgrad",
                "enum": ["low", "high", "xhigh"]
              }
            }
          }
        }
      },
      "VideoContent": {
        "title": "Videoinhalt",
        "type": "object",
        "required": ["type", "video_url"],
        "properties": {
          "type": {
            "type": "string",
            "enum": ["video_url"],
            "description": "Inhaltstyp"
          },
          "video_url": {
            "type": "object",
            "required": ["url"],
            "properties": {
              "url": {
                "type": "string",
                "format": "uri",
                "description": "Video-URL-Adresse oder Base64-Kodierung\n\n**Unterstuetzte Formate**:\n- Videolink (oeffentlich zugaenglich)\n- Base64-Kodierung des Videos\n\n**Hinweis**: Audioinhalte im Video werden nicht unterstuetzt",
                "example": "https://example.com/video.mp4"
              },
              "fps": {
                "type": "number",
                "nullable": true,
                "description": "Frame-Extraktionsrate\n\n- Wertebereich: [0.2, 5]\n- Hoehere Werte: Empfindlicher gegenueber Bildaenderungen im Video\n- Niedrigere Werte: Weniger empfindlich gegenueber Bildaenderungen, aber weniger Token-Verbrauch und schneller",
                "minimum": 0.2,
                "maximum": 5,
                "default": 1,
                "example": 1
              }
            }
          }
        }
      },
      "Tool": {
        "type": "object",
        "required": ["type", "function"],
        "properties": {
          "type": {
            "type": "string",
            "description": "Werkzeugtyp, derzeit wird nur function unterstuetzt",
            "enum": ["function"]
          },
          "function": {
            "type": "object",
            "required": ["name"],
            "description": "Funktionsdefinition",
            "properties": {
              "name": {
                "type": "string",
                "description": "Name der aufzurufenden Funktion"
              },
              "description": {
                "type": "string",
                "description": "Beschreibung der Funktion, das Modell verwendet diese, um zu entscheiden, ob dieses Werkzeug aufgerufen werden soll"
              },
              "parameters": {
                "type": "object",
                "description": "Funktionsanfrageparameter, beschrieben im JSON-Schema-Format\n\n**Hinweis**:\n- Alle Feldnamen sind gross-/kleinschreibungssensitiv\n- parameters muss ein gueltiges JSON-Schema-Objekt sein\n- Es wird empfohlen, englische Feldnamen zu verwenden und Chinesisch im description-Feld zu platzieren"
              }
            }
          }
        }
      },
      "ToolChoiceObject": {
        "type": "object",
        "required": ["type", "function"],
        "description": "Bereich der aufzurufenden Werkzeuge festlegen",
        "properties": {
          "type": {
            "type": "string",
            "description": "Aufruftyp",
            "enum": ["function"]
          },
          "function": {
            "type": "object",
            "required": ["name"],
            "properties": {
              "name": {
                "type": "string",
                "description": "Name des aufzurufenden Werkzeugs"
              }
            }
          }
        }
      },
      "ToolCall": {
        "type": "object",
        "properties": {
          "id": {
            "type": "string",
            "description": "ID des aufgerufenen Werkzeugs, vom Modell generiert"
          },
          "type": {
            "type": "string",
            "description": "Werkzeugtyp, derzeit wird nur function unterstuetzt",
            "enum": ["function"]
          },
          "function": {
            "type": "object",
            "properties": {
              "name": {
                "type": "string",
                "description": "Name der aufzurufenden Funktion"
              },
              "arguments": {
                "type": "string",
                "description": "Eingangsparameter der aufzurufenden Funktion, im JSON-Format\n\n**Hinweis**: Das Modell generiert nicht immer gueltiges JSON und kann undefinierte Parameter erfinden. Es wird empfohlen, die Parameter vor dem Funktionsaufruf zu validieren"
              }
            }
          }
        }
      },
      "ChatCompletionResponse": {
        "type": "object",
        "properties": {
          "id": {
            "type": "string",
            "description": "Eindeutige Kennung dieser Anfrage",
            "example": "0217714854126607f5a9cf8ed5b018c76e4ad3dc2810db57ffb50"
          },
          "model": {
            "type": "string",
            "description": "Tatsaechlich verwendeter Modellname und Version dieser Anfrage",
            "example": "doubao-seed-2-0-pro-260215"
          },
          "object": {
            "type": "string",
            "enum": ["chat.completion"],
            "description": "Antworttyp, fester Wert chat.completion",
            "example": "chat.completion"
          },
          "service_tier": {
            "type": "string",
            "description": "Service-Stufe dieser Anfrage\n\n- `default`: Standard-Service-Stufe\n- `scale`: Garantiepaket-Kontingent verwendet",
            "enum": ["default", "scale"],
            "example": "default"
          },
          "created": {
            "type": "integer",
            "description": "Unix-Zeitstempel der Anfrageerstellung (Sekunden)",
            "example": 1771485416
          },
          "choices": {
            "type": "array",
            "description": "Modellausgabeinhalt dieser Anfrage",
            "items": {
              "$ref": "#/components/schemas/Choice"
            }
          },
          "usage": {
            "$ref": "#/components/schemas/Usage"
          }
        }
      },
      "Choice": {
        "type": "object",
        "properties": {
          "index": {
            "type": "integer",
            "description": "Index des aktuellen Elements in der choices-Liste",
            "example": 0
          },
          "message": {
            "$ref": "#/components/schemas/AssistantMessage"
          },
          "finish_reason": {
            "type": "string",
            "description": "Grund fuer das Stoppen der Token-Generierung\n\n- `stop`: Modellausgabe natuerlich beendet oder durch stop-Parameter abgeschnitten\n- `length`: Modellausgabe durch max_tokens / max_completion_tokens / Kontextlaengenlimit abgeschnitten\n- `content_filter`: Modellausgabe durch Inhaltsmoderation blockiert\n- `tool_calls`: Modell hat ein Werkzeug aufgerufen",
            "enum": ["stop", "length", "content_filter", "tool_calls"],
            "example": "stop"
          },
          "logprobs": {
            "type": "object",
            "nullable": true,
            "description": "Log-Wahrscheinlichkeitsinformationen des aktuellen Inhalts",
            "properties": {
              "content": {
                "type": "array",
                "nullable": true,
                "description": "Token-Log-Wahrscheinlichkeitsinformationen fuer jedes content-Element",
                "items": {
                  "$ref": "#/components/schemas/LogprobContent"
                }
              }
            }
          },
          "moderation_hit_type": {
            "type": "string",
            "nullable": true,
            "description": "Wenn die Modellausgabe sensible Informationen enthaelt, wird die getroffene Risikokategorie zurueckgegeben\n\n- `severe_violation`: Modellausgabe enthaelt schwere Verstoesse\n- `violence`: Modellausgabe enthaelt aggressive Inhalte",
            "enum": ["severe_violation", "violence"]
          }
        }
      },
      "AssistantMessage": {
        "type": "object",
        "properties": {
          "role": {
            "type": "string",
            "description": "Ausgaberolle, fester Wert assistant",
            "enum": ["assistant"],
            "example": "assistant"
          },
          "content": {
            "type": "string",
            "description": "Vom Modell generierter Nachrichteninhalt",
            "example": "Hallo! Doubao Seed 2.0 ist ein von ByteDance entwickeltes Sprachmodell der neuen Generation mit staerkeren Reasoning-, multimodalen Verstaendnis- und Tiefes-Denken-Faehigkeiten."
          },
          "reasoning_content": {
            "type": "string",
            "nullable": true,
            "description": "Chain-of-Thought-Inhalt der Modellverarbeitung\n\nWird nur bei aktiviertem Tiefes-Denken-Modus zurueckgegeben"
          },
          "tool_calls": {
            "type": "array",
            "nullable": true,
            "description": "Vom Modell generierte Werkzeugaufrufe",
            "items": {
              "$ref": "#/components/schemas/ToolCall"
            }
          }
        }
      },
      "LogprobContent": {
        "type": "object",
        "properties": {
          "token": {
            "type": "string",
            "description": "Aktueller Token"
          },
          "bytes": {
            "type": "array",
            "nullable": true,
            "description": "UTF-8-Wert des aktuellen Tokens, als Integer-Liste",
            "items": {
              "type": "integer"
            }
          },
          "logprob": {
            "type": "number",
            "description": "Log-Wahrscheinlichkeit des aktuellen Tokens"
          },
          "top_logprobs": {
            "type": "array",
            "description": "Liste der wahrscheinlichsten Token und ihrer Log-Wahrscheinlichkeiten an der aktuellen Token-Position",
            "items": {
              "type": "object",
              "properties": {
                "token": {
                  "type": "string",
                  "description": "Aktueller Token"
                },
                "bytes": {
                  "type": "array",
                  "nullable": true,
                  "description": "UTF-8-Wert des aktuellen Tokens",
                  "items": {
                    "type": "integer"
                  }
                },
                "logprob": {
                  "type": "number",
                  "description": "Log-Wahrscheinlichkeit des aktuellen Tokens"
                }
              }
            }
          }
        }
      },
      "Usage": {
        "type": "object",
        "description": "Token-Verbrauch dieser Anfrage",
        "properties": {
          "total_tokens": {
            "type": "integer",
            "description": "Gesamtanzahl der verbrauchten Token dieser Anfrage (Eingabe + Ausgabe)",
            "example": 271
          },
          "prompt_tokens": {
            "type": "integer",
            "description": "Anzahl der Token des an das Modell uebergebenen Inhalts",
            "example": 15
          },
          "prompt_tokens_details": {
            "type": "object",
            "description": "Details zur Eingabe-Token-Anzahl",
            "properties": {
              "cached_tokens": {
                "type": "integer",
                "description": "Token-Verbrauch fuer gecachten Eingabeinhalt",
                "example": 0
              }
            }
          },
          "completion_tokens": {
            "type": "integer",
            "description": "Token-Verbrauch fuer die Modellausgabe",
            "example": 256
          },
          "completion_tokens_details": {
            "type": "object",
            "description": "Details zum Ausgabe-Token-Verbrauch",
            "properties": {
              "reasoning_tokens": {
                "type": "integer",
                "description": "Token-Verbrauch fuer Chain-of-Thought-Ausgabe",
                "example": 0
              }
            }
          }
        }
      },
      "ErrorResponse": {
        "type": "object",
        "properties": {
          "error": {
            "type": "object",
            "properties": {
              "code": {
                "type": "integer",
                "description": "HTTP-Status-Fehlercode"
              },
              "message": {
                "type": "string",
                "description": "Fehlerbeschreibung"
              },
              "type": {
                "type": "string",
                "description": "Fehlertyp"
              },
              "param": {
                "type": "string",
                "description": "Zugehoeriger Parametername"
              },
              "fallback_suggestion": {
                "type": "string",
                "description": "Vorschlag bei Fehler"
              }
            }
          }
        }
      }
    },
    "securitySchemes": {
      "bearerAuth": {
        "type": "http",
        "scheme": "bearer",
        "description": "##Alle APIs erfordern Bearer-Token-Authentifizierung##\n\n**API-Schluessel erhalten:**\n\nBesuchen Sie die [API-Schluesselverwaltungsseite](https://evolink.ai/dashboard/keys), um Ihren API-Schluessel zu erhalten\n\n**Zum Anfrage-Header hinzufuegen:**\n```\nAuthorization: Bearer YOUR_API_KEY\n```"
      }
    }
  },
  "tags": [
    {
      "name": "Chat-Generierung",
      "description": "KI-Chat-Generierung zugehoerige APIs"
    }
  ]
}