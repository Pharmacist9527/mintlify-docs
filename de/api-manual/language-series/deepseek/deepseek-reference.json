{
  "openapi": "3.1.0",
  "info": {
    "title": "DeepSeek Vollständige API-Referenz",
    "description": "Vollständige API-Referenz für die DeepSeek-Chat-Schnittstelle, einschließlich aller Parameter und erweiterten Funktionen",
    "license": {
      "name": "MIT"
    },
    "version": "1.0.0"
  },
  "servers": [
    {
      "url": "https://api.evolink.ai",
      "description": "Produktionsumgebung"
    }
  ],
  "security": [
    {
      "bearerAuth": []
    }
  ],
  "paths": {
    "/v1/chat/completions": {
      "post": {
        "summary": "DeepSeek Chat API",
        "description": "- DeepSeek-Modelle im OpenAI-SDK-Format aufrufen\n- Synchroner Verarbeitungsmodus, Echtzeit-Antwort\n- Unterstützt `deepseek-chat` (allgemeine Konversation) und `deepseek-reasoner` (tiefes Denken) Modelle\n- **Text-Chat**: Einzel- oder Mehrrundenkonversation mit Kontext\n- **System-Prompts**: KI-Rolle und -Verhalten anpassen\n- **Streaming**: SSE-Streaming-Ausgabeunterstützung\n- **Tool Calling**: Function-Calling-Unterstützung",
        "operationId": "createChatCompletionDeepSeek",
        "tags": [
          "Chat-Vervollständigung"
        ],
        "requestBody": {
          "required": true,
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/ChatCompletionRequest"
              },
              "examples": {
                "simple_text": {
                  "summary": "Einfacher Text-Chat",
                  "value": {
                    "model": "deepseek-chat",
                    "messages": [
                      {
                        "role": "user",
                        "content": "Tell me about yourself"
                      }
                    ]
                  }
                },
                "multi_turn": {
                  "summary": "Mehrrunden-Konversation",
                  "value": {
                    "model": "deepseek-chat",
                    "messages": [
                      {
                        "role": "user",
                        "content": "What is Python?"
                      },
                      {
                        "role": "assistant",
                        "content": "Python is a high-level programming language..."
                      },
                      {
                        "role": "user",
                        "content": "What are its advantages?"
                      }
                    ]
                  }
                },
                "system_prompt": {
                  "summary": "System-Prompt verwenden",
                  "value": {
                    "model": "deepseek-chat",
                    "messages": [
                      {
                        "role": "system",
                        "content": "You are a professional Python programming assistant. Answer questions concisely."
                      },
                      {
                        "role": "user",
                        "content": "How to read a file?"
                      }
                    ]
                  }
                },
                "reasoner": {
                  "summary": "Tiefes Denkmodell verwenden",
                  "value": {
                    "model": "deepseek-reasoner",
                    "messages": [
                      {
                        "role": "user",
                        "content": "Prove that the square root of 2 is irrational"
                      }
                    ]
                  }
                }
              }
            }
          }
        },
        "responses": {
          "200": {
            "description": "Chat-Vervollständigung erfolgreich generiert",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ChatCompletionResponse"
                }
              }
            }
          },
          "400": {
            "description": "Ungültige Anfrageparameter",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                },
                "example": {
                  "error": {
                    "code": 400,
                    "message": "Ungültige Anfrageparameter",
                    "type": "invalid_request_error"
                  }
                }
              }
            }
          },
          "401": {
            "description": "Nicht authentifiziert, ungültiger oder abgelaufener Token",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                },
                "example": {
                  "error": {
                    "code": 401,
                    "message": "Invalid or expired token",
                    "type": "authentication_error"
                  }
                }
              }
            }
          },
          "402": {
            "description": "Unzureichendes Kontingent, Aufladung erforderlich",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                },
                "example": {
                  "error": {
                    "code": 402,
                    "message": "Unzureichendes Kontingent",
                    "type": "insufficient_quota_error"
                  }
                }
              }
            }
          },
          "403": {
            "description": "Zugriff verweigert",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                },
                "example": {
                  "error": {
                    "code": 403,
                    "message": "Access denied for this model",
                    "type": "permission_error",
                    "param": "model"
                  }
                }
              }
            }
          },
          "404": {
            "description": "Ressource nicht gefunden",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                },
                "example": {
                  "error": {
                    "code": 404,
                    "message": "Specified model not found",
                    "type": "not_found_error",
                    "param": "model"
                  }
                }
              }
            }
          },
          "413": {
            "description": "Anfragekörper zu groß",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                },
                "example": {
                  "error": {
                    "code": 413,
                    "message": "Anfragekörper zu groß",
                    "type": "request_too_large_error",
                    "param": "messages"
                  }
                }
              }
            }
          },
          "429": {
            "description": "Ratenlimit überschritten",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                },
                "example": {
                  "error": {
                    "code": 429,
                    "message": "Ratenlimit überschritten",
                    "type": "rate_limit_error"
                  }
                }
              }
            }
          },
          "500": {
            "description": "Interner Serverfehler",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                },
                "example": {
                  "error": {
                    "code": 500,
                    "message": "Interner Serverfehler",
                    "type": "internal_server_error"
                  }
                }
              }
            }
          },
          "502": {
            "description": "Upstream-Dienstfehler",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                },
                "example": {
                  "error": {
                    "code": 502,
                    "message": "Upstream AI service unavailable",
                    "type": "upstream_error"
                  }
                }
              }
            }
          },
          "503": {
            "description": "Dienst vorübergehend nicht verfügbar",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                },
                "example": {
                  "error": {
                    "code": 503,
                    "message": "Dienst vorübergehend nicht verfügbar",
                    "type": "service_unavailable_error"
                  }
                }
              }
            }
          }
        }
      }
    }
  },
  "components": {
    "schemas": {
      "ChatCompletionRequest": {
        "type": "object",
        "required": [
          "model",
          "messages"
        ],
        "properties": {
          "model": {
            "type": "string",
            "description": "Chat-Modellname\n\n- `deepseek-chat`: Allgemeines Konversationsmodell\n- `deepseek-reasoner`: Tiefes Denkmodell, hervorragend in Mathematik, Programmierung und komplexem logischem Denken\n\n**Hinweis**: `deepseek-reasoner` unterstützt die Parameter `temperature`, `top_p`, `tools`, `tool_choice`, `response_format` nicht. Die Übergabe dieser Parameter wird vom Upstream abgelehnt",
            "enum": [
              "deepseek-chat",
              "deepseek-reasoner"
            ],
            "default": "deepseek-chat",
            "example": "deepseek-chat"
          },
          "messages": {
            "type": "array",
            "description": "Konversationsnachrichtenliste, unterstützt Mehrrunden-Konversation\n\nVerschiedene Rollen haben unterschiedliche Feldstrukturen, wählen Sie die entsprechende Rolle zur Ansicht",
            "items": {
              "oneOf": [
                {
                  "$ref": "#/components/schemas/SystemMessage"
                },
                {
                  "$ref": "#/components/schemas/UserMessage"
                },
                {
                  "$ref": "#/components/schemas/AssistantRequestMessage"
                },
                {
                  "$ref": "#/components/schemas/ToolMessage"
                }
              ],
              "discriminator": {
                "propertyName": "role",
                "mapping": {
                  "system": "#/components/schemas/SystemMessage",
                  "user": "#/components/schemas/UserMessage",
                  "assistant": "#/components/schemas/AssistantRequestMessage",
                  "tool": "#/components/schemas/ToolMessage"
                }
              }
            },
            "minItems": 1
          },
          "thinking": {
            "type": "object",
            "description": "Denkmodus-Steuerung (Beta)\n\n**Details**:\n- Steuert die Tiefdenk-Funktion des `deepseek-reasoner`-Modells\n- Wenn aktiviert, führt das Modell vor der Antwort tiefes Denken durch",
            "properties": {
              "type": {
                "type": "string",
                "description": "Denkmodus-Schalter\n\n- `enabled`: Tiefes Denken aktivieren\n- `disabled`: Tiefes Denken deaktivieren",
                "enum": [
                  "enabled",
                  "disabled"
                ]
              }
            }
          },
          "frequency_penalty": {
            "type": "number",
            "description": "Frequenzstrafe-Parameter zur Reduzierung repetitiver Inhalte\n\n**Details**:\n- Positive Werte bestrafen Tokens basierend auf ihrer Häufigkeit im generierten Text\n- Höhere Werte machen es unwahrscheinlicher, bestehende Inhalte zu wiederholen\n- Standard: 0 (keine Strafe)",
            "minimum": -2,
            "maximum": 2,
            "default": 0,
            "example": 0
          },
          "max_tokens": {
            "type": "integer",
            "description": "Maximale Anzahl der zu generierenden Tokens\n\n**Details**:\n- Das Modell stoppt die Generierung, wenn dieses Limit erreicht ist\n- Wenn nicht gesetzt, entscheidet das Modell über die Generierungslänge",
            "minimum": 1,
            "example": 4096
          },
          "presence_penalty": {
            "type": "number",
            "description": "Präsenzstrafe-Parameter zur Förderung neuer Themen\n\n**Details**:\n- Positive Werte bestrafen Tokens basierend darauf, ob sie im Text vorgekommen sind\n- Höhere Werte fördern die Diskussion neuer Themen\n- Standard: 0 (keine Strafe)",
            "minimum": -2,
            "maximum": 2,
            "default": 0,
            "example": 0
          },
          "response_format": {
            "type": "object",
            "description": "Antwortformat angeben\n\n**Details**:\n- Auf `{\"type\": \"json_object\"}` setzen, um den JSON-Modus zu aktivieren\n- Im JSON-Modus gibt das Modell gültigen JSON-Inhalt aus",
            "properties": {
              "type": {
                "type": "string",
                "enum": [
                  "text",
                  "json_object"
                ],
                "description": "Antwortformat-Typ",
                "default": "text"
              }
            }
          },
          "stop": {
            "description": "Stoppsequenzen. Das Modell stoppt die Generierung, wenn es auf diese Zeichenketten trifft\n\n**Details**:\n- Kann eine einzelne Zeichenkette oder ein Array von Zeichenketten sein\n- Maximal 16 Stoppsequenzen",
            "oneOf": [
              {
                "type": "string"
              },
              {
                "type": "array",
                "items": {
                  "type": "string"
                },
                "maxItems": 16
              }
            ]
          },
          "stream": {
            "type": "boolean",
            "description": "Ob die Antwort gestreamt werden soll\n\n- `true`: Streaming über SSE (Server-Sent Events), Inhalte werden in Echtzeit-Blöcken zurückgegeben\n- `false`: Auf die vollständige Antwort warten, bevor sie zurückgegeben wird",
            "default": false,
            "example": false
          },
          "stream_options": {
            "type": "object",
            "description": "Streaming-Antwortoptionen\n\nNur wirksam, wenn `stream=true`",
            "properties": {
              "include_usage": {
                "type": "boolean",
                "description": "Nutzungsstatistiken am Ende des Streams zurückgeben"
              }
            }
          },
          "temperature": {
            "type": "number",
            "description": "Sampling-Temperatur, steuert die Zufälligkeit der Ausgabe\n\n**Details**:\n- Niedrigere Werte (z.B. 0.2): Deterministischere, fokussiertere Ausgabe\n- Höhere Werte (z.B. 1.5): Zufälligere, kreativere Ausgabe\n- Standard: 1",
            "minimum": 0,
            "maximum": 2,
            "default": 1,
            "example": 1
          },
          "top_p": {
            "type": "number",
            "description": "Nucleus-Sampling-Parameter\n\n**Details**:\n- Steuert das Sampling von Tokens, deren kumulative Wahrscheinlichkeit den Schwellenwert erreicht\n- Zum Beispiel bedeutet 0.9, dass aus Tokens mit 90% kumulativer Wahrscheinlichkeit gesampelt wird\n- Standard: 1.0 (alle Tokens berücksichtigen)\n\n**Tipp**: Vermeiden Sie es, temperature und top_p gleichzeitig anzupassen",
            "minimum": 0,
            "maximum": 1,
            "default": 1,
            "example": 1
          },
          "tools": {
            "type": "array",
            "description": "Tool-Definitionsliste für Function Calling\n\n**Details**:\n- Maximal 128 Tool-Definitionen\n- Jedes Tool erfordert einen Namen, eine Beschreibung und ein Parameterschema",
            "items": {
              "$ref": "#/components/schemas/Tool"
            },
            "maxItems": 128
          },
          "tool_choice": {
            "description": "Steuert das Verhalten von Tool-Aufrufen\n\n**Optionen**:\n- `none`: Keine Tools aufrufen\n- `auto`: Modell entscheidet, ob Tools aufgerufen werden\n- `required`: Modell wird gezwungen, ein oder mehrere Tools aufzurufen\n\n**Standard**: `none` wenn keine Tools bereitgestellt werden, `auto` wenn Tools bereitgestellt werden",
            "oneOf": [
              {
                "type": "string",
                "enum": [
                  "none",
                  "auto",
                  "required"
                ]
              },
              {
                "type": "object",
                "description": "Ein bestimmtes Tool zum Aufrufen angeben",
                "properties": {
                  "type": {
                    "type": "string",
                    "enum": [
                      "function"
                    ]
                  },
                  "function": {
                    "type": "object",
                    "properties": {
                      "name": {
                        "type": "string",
                        "description": "Name der aufzurufenden Funktion"
                      }
                    },
                    "required": [
                      "name"
                    ]
                  }
                }
              }
            ]
          },
          "logprobs": {
            "type": "boolean",
            "description": "Ob Token-Log-Wahrscheinlichkeiten zurückgegeben werden sollen\n\n**Details**:\n- Wenn auf `true` gesetzt, enthält die Antwort Log-Wahrscheinlichkeitsinformationen für jedes Token",
            "default": false
          },
          "top_logprobs": {
            "type": "integer",
            "description": "Log-Wahrscheinlichkeiten der N wahrscheinlichsten Tokens zurückgeben\n\n**Details**:\n- Erfordert, dass `logprobs` auf `true` gesetzt ist\n- Bereich: `[0, 20]`",
            "minimum": 0,
            "maximum": 20
          }
        }
      },
      "SystemMessage": {
        "title": "Systemnachricht",
        "type": "object",
        "required": [
          "role",
          "content"
        ],
        "properties": {
          "role": {
            "type": "string",
            "enum": [
              "system"
            ],
            "description": "Rollenbezeichner, fest als `system`"
          },
          "content": {
            "type": "string",
            "description": "System-Prompt-Inhalt, wird verwendet, um die KI-Rolle und das Verhalten zu definieren"
          },
          "name": {
            "type": "string",
            "description": "Teilnehmername, wird verwendet, um verschiedene System-Prompt-Quellen zu unterscheiden"
          }
        }
      },
      "UserMessage": {
        "title": "Benutzernachricht",
        "type": "object",
        "required": [
          "role",
          "content"
        ],
        "properties": {
          "role": {
            "type": "string",
            "enum": [
              "user"
            ],
            "description": "Rollenbezeichner, fest als `user`"
          },
          "content": {
            "type": "string",
            "description": "Benutzernachrichteninhalt (Klartext-Zeichenkette)"
          },
          "name": {
            "type": "string",
            "description": "Teilnehmername, wird verwendet, um verschiedene Benutzer zu unterscheiden"
          }
        }
      },
      "AssistantRequestMessage": {
        "title": "Assistenten-Nachricht",
        "type": "object",
        "required": [
          "role",
          "content"
        ],
        "properties": {
          "role": {
            "type": "string",
            "enum": [
              "assistant"
            ],
            "description": "Rollenbezeichner, fest als `assistant`"
          },
          "content": {
            "type": [
              "string",
              "null"
            ],
            "description": "Assistenten-Nachrichteninhalt\n\n**Details**:\n- Wird verwendet, um historische Assistenten-Antworten in mehrstufigen Konversationen zu übergeben\n- Kann `null` sein, wenn `tool_calls` vorhanden ist"
          },
          "name": {
            "type": "string",
            "description": "Teilnehmername"
          },
          "prefix": {
            "type": "boolean",
            "description": "Präfix-Fortsetzungsmodus aktivieren (Beta)\n\n**Details**:\n- Nur bei der letzten Nachricht\n- Wenn `true`, generiert das Modell weiter ab dem `content` dieser Nachricht als Präfix",
            "default": false
          },
          "reasoning_content": {
            "type": [
              "string",
              "null"
            ],
            "description": "Chain-of-Thought-Inhalt (Beta)\n\n**Details**:\n- Nur wirksam bei Verwendung des `deepseek-reasoner`-Modells\n- Wird verwendet, um den historischen Denkprozess in mehrstufigen Konversationen zu übergeben\n- Erfordert, dass `prefix` auf `true` gesetzt ist"
          },
          "tool_calls": {
            "type": "array",
            "description": "Tool-Aufrufliste\n\nWird verwendet, um historische Tool-Aufrufinformationen in mehrstufigen Konversationen zu übergeben",
            "items": {
              "type": "object",
              "properties": {
                "id": {
                  "type": "string",
                  "description": "Eindeutiger Bezeichner für den Tool-Aufruf"
                },
                "type": {
                  "type": "string",
                  "enum": [
                    "function"
                  ]
                },
                "function": {
                  "type": "object",
                  "properties": {
                    "name": {
                      "type": "string",
                      "description": "Name der aufgerufenen Funktion"
                    },
                    "arguments": {
                      "type": "string",
                      "description": "Funktionsargumente (JSON-Zeichenkette)"
                    }
                  }
                }
              }
            }
          }
        }
      },
      "ToolMessage": {
        "title": "Werkzeugnachricht",
        "type": "object",
        "required": [
          "role",
          "content",
          "tool_call_id"
        ],
        "properties": {
          "role": {
            "type": "string",
            "enum": [
              "tool"
            ],
            "description": "Rollenbezeichner, fest als `tool`"
          },
          "content": {
            "type": "string",
            "description": "Ergebnis des Tool-Aufrufs"
          },
          "tool_call_id": {
            "type": "string",
            "description": "Tool-Aufruf-ID\n\nEntspricht dem `id`-Feld, das in den `tool_calls` der Assistenten-Nachricht zurückgegeben wird"
          }
        }
      },
      "Tool": {
        "type": "object",
        "required": [
          "type",
          "function"
        ],
        "properties": {
          "type": {
            "type": "string",
            "enum": [
              "function"
            ],
            "description": "Tool-Typ, derzeit wird nur `function` unterstützt"
          },
          "function": {
            "type": "object",
            "required": [
              "name"
            ],
            "properties": {
              "name": {
                "type": "string",
                "description": "Name der aufzurufenden Funktion\n\n**Details**:\n- Muss aus den Zeichen a-z, A-Z, 0-9 bestehen oder Unterstriche und Bindestriche enthalten\n- Maximale Länge von 64 Zeichen"
              },
              "description": {
                "type": "string",
                "description": "Funktionsbeschreibung, hilft dem Modell zu verstehen, wann und wie diese Funktion aufgerufen werden soll"
              },
              "parameters": {
                "type": "object",
                "description": "Funktions-Eingabeparameter, beschrieben als JSON-Schema-Objekt\n\n**Details**:\n- Das Weglassen von `parameters` definiert eine Funktion mit einer leeren Parameterliste"
              },
              "strict": {
                "type": "boolean",
                "description": "Strikten Modus aktivieren (Beta)\n\n**Details**:\n- Wenn auf `true` gesetzt, verwendet die API den strikten Modus für Funktionsaufrufe\n- Stellt sicher, dass die Ausgabe immer der JSON-Schema-Definition der Funktion entspricht",
                "default": false
              }
            }
          }
        }
      },
      "ChatCompletionResponse": {
        "type": "object",
        "properties": {
          "id": {
            "type": "string",
            "description": "Eindeutiger Bezeichner für die Chat-Vervollständigung",
            "example": "930c60df-bf64-41c9-a88e-3ec75f81e00e"
          },
          "model": {
            "type": "string",
            "description": "Tatsächlich verwendeter Modellname",
            "example": "deepseek-chat"
          },
          "object": {
            "type": "string",
            "enum": [
              "chat.completion"
            ],
            "description": "Antworttyp",
            "example": "chat.completion"
          },
          "created": {
            "type": "integer",
            "description": "Erstellungszeitstempel",
            "example": 1770617860
          },
          "choices": {
            "type": "array",
            "description": "Liste der Chat-Vervollständigungsoptionen",
            "items": {
              "$ref": "#/components/schemas/Choice"
            }
          },
          "usage": {
            "$ref": "#/components/schemas/Usage"
          },
          "system_fingerprint": {
            "type": "string",
            "description": "System-Fingerabdruck-Bezeichner",
            "example": "fp_eaab8d114b_prod0820_fp8_kvcache"
          }
        }
      },
      "Choice": {
        "type": "object",
        "properties": {
          "index": {
            "type": "integer",
            "description": "Auswahlindex",
            "example": 0
          },
          "message": {
            "$ref": "#/components/schemas/AssistantMessage"
          },
          "finish_reason": {
            "type": "string",
            "description": "Abschlussgrund\n\n- `stop`: Natürlicher Abschluss oder Stoppsequenz erreicht\n- `length`: Maximales Token-Limit erreicht\n- `content_filter`: Ausgabe durch Sicherheitsrichtlinie gefiltert\n- `tool_calls`: Modell hat ein Tool aufgerufen\n- `insufficient_system_resource`: Backend-Ressourcenbeschränkungen",
            "enum": [
              "stop",
              "length",
              "content_filter",
              "tool_calls",
              "insufficient_system_resource"
            ],
            "example": "stop"
          }
        }
      },
      "AssistantMessage": {
        "type": "object",
        "properties": {
          "role": {
            "type": "string",
            "description": "Rolle des Nachrichtenabsenders",
            "enum": [
              "assistant"
            ],
            "example": "assistant"
          },
          "content": {
            "type": "string",
            "description": "KI-Antwortinhalt",
            "example": "Hello! I'm DeepSeek, a powerful AI assistant. I excel at general conversation, code generation, mathematical reasoning and many other tasks."
          },
          "reasoning_content": {
            "type": "string",
            "description": "Inhalt des Denkprozesses (wird nur vom `deepseek-reasoner`-Modell zurückgegeben)\n\n**Details**:\n- Enthält den Chain-of-Thought-Prozess des Modells\n- Wird nur bei Verwendung des `deepseek-reasoner`-Modells zurückgegeben",
            "example": "Let me analyze this problem..."
          },
          "tool_calls": {
            "type": "array",
            "description": "Tool-Aufrufliste (wird zurückgegeben, wenn das Modell entscheidet, ein Tool aufzurufen)",
            "items": {
              "type": "object",
              "properties": {
                "id": {
                  "type": "string",
                  "description": "Eindeutiger Bezeichner für den Tool-Aufruf"
                },
                "type": {
                  "type": "string",
                  "enum": [
                    "function"
                  ]
                },
                "function": {
                  "type": "object",
                  "properties": {
                    "name": {
                      "type": "string",
                      "description": "Name der aufgerufenen Funktion"
                    },
                    "arguments": {
                      "type": "string",
                      "description": "Funktionsargumente (JSON-Zeichenkette)"
                    }
                  }
                }
              }
            }
          }
        }
      },
      "Usage": {
        "type": "object",
        "description": "Token-Nutzungsstatistiken",
        "properties": {
          "prompt_tokens": {
            "type": "integer",
            "description": "Anzahl der Tokens in der Eingabe",
            "example": 16
          },
          "completion_tokens": {
            "type": "integer",
            "description": "Anzahl der Tokens in der Ausgabe",
            "example": 10
          },
          "total_tokens": {
            "type": "integer",
            "description": "Gesamtanzahl der Tokens",
            "example": 26
          },
          "prompt_cache_hit_tokens": {
            "type": "integer",
            "description": "Anzahl der Cache-Treffer-Tokens in der Eingabe",
            "example": 0
          },
          "prompt_cache_miss_tokens": {
            "type": "integer",
            "description": "Anzahl der Cache-Fehlschlag-Tokens in der Eingabe",
            "example": 16
          }
        }
      },
      "ErrorResponse": {
        "type": "object",
        "properties": {
          "error": {
            "type": "object",
            "properties": {
              "code": {
                "type": "integer",
                "description": "HTTP-Status-Fehlercode"
              },
              "message": {
                "type": "string",
                "description": "Fehlerbeschreibung"
              },
              "type": {
                "type": "string",
                "description": "Fehlertyp"
              },
              "param": {
                "type": "string",
                "description": "Zugehöriger Parametername"
              }
            }
          }
        }
      }
    },
    "securitySchemes": {
      "bearerAuth": {
        "type": "http",
        "scheme": "bearer",
        "description": "##Alle APIs erfordern Bearer-Token-Authentifizierung##\n\n**API-Schlüssel erhalten:**\n\nBesuchen Sie die [API-Schlüsselverwaltungsseite](https://evolink.ai/dashboard/keys), um Ihren API-Schlüssel zu erhalten\n\n**Zum Anfrage-Header hinzufügen:**\n```\nAuthorization: Bearer YOUR_API_KEY\n```"
      }
    }
  },
  "tags": [
    {
      "name": "Chat-Vervollständigung",
      "description": "KI-Chat-Vervollständigung zugehörige APIs"
    }
  ]
}