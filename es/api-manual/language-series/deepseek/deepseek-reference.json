{
  "openapi": "3.1.0",
  "info": {
    "title": "Referencia completa de la API de DeepSeek",
    "description": "Referencia completa de la API para la interfaz de chat de DeepSeek, incluyendo todos los parámetros y funciones avanzadas",
    "license": {
      "name": "MIT"
    },
    "version": "1.0.0"
  },
  "servers": [
    {
      "url": "https://api.evolink.ai",
      "description": "Entorno de producción"
    }
  ],
  "security": [
    {
      "bearerAuth": []
    }
  ],
  "paths": {
    "/v1/chat/completions": {
      "post": {
        "summary": "API de chat de DeepSeek",
        "description": "- Llama a los modelos DeepSeek usando el formato OpenAI SDK\n- Modo de procesamiento síncrono, respuesta en tiempo real\n- Compatible con los modelos `deepseek-chat` (conversación general) y `deepseek-reasoner` (razonamiento profundo)\n- **Chat de texto**: Conversación contextual de uno o varios turnos\n- **Prompts del sistema**: Personaliza el rol y comportamiento de la IA\n- **Streaming**: Soporte de salida en streaming SSE\n- **Llamada de herramientas**: Soporte de Function Calling",
        "operationId": "createChatCompletionDeepSeek",
        "tags": [
          "Completado de chat"
        ],
        "requestBody": {
          "required": true,
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/ChatCompletionRequest"
              },
              "examples": {
                "simple_text": {
                  "summary": "Chat de texto simple",
                  "value": {
                    "model": "deepseek-chat",
                    "messages": [
                      {
                        "role": "user",
                        "content": "Tell me about yourself"
                      }
                    ]
                  }
                },
                "multi_turn": {
                  "summary": "Conversación multi-turno",
                  "value": {
                    "model": "deepseek-chat",
                    "messages": [
                      {
                        "role": "user",
                        "content": "What is Python?"
                      },
                      {
                        "role": "assistant",
                        "content": "Python is a high-level programming language..."
                      },
                      {
                        "role": "user",
                        "content": "What are its advantages?"
                      }
                    ]
                  }
                },
                "system_prompt": {
                  "summary": "Usando prompt del sistema",
                  "value": {
                    "model": "deepseek-chat",
                    "messages": [
                      {
                        "role": "system",
                        "content": "You are a professional Python programming assistant. Answer questions concisely."
                      },
                      {
                        "role": "user",
                        "content": "How to read a file?"
                      }
                    ]
                  }
                },
                "reasoner": {
                  "summary": "Usando modelo de razonamiento profundo",
                  "value": {
                    "model": "deepseek-reasoner",
                    "messages": [
                      {
                        "role": "user",
                        "content": "Prove that the square root of 2 is irrational"
                      }
                    ]
                  }
                }
              }
            }
          }
        },
        "responses": {
          "200": {
            "description": "Completado de chat generado exitosamente",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ChatCompletionResponse"
                }
              }
            }
          },
          "400": {
            "description": "Parámetros de solicitud inválidos",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                },
                "example": {
                  "error": {
                    "code": 400,
                    "message": "Parámetros de solicitud inválidos",
                    "type": "invalid_request_error"
                  }
                }
              }
            }
          },
          "401": {
            "description": "No autenticado, token inválido o expirado",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                },
                "example": {
                  "error": {
                    "code": 401,
                    "message": "Invalid or expired token",
                    "type": "authentication_error"
                  }
                }
              }
            }
          },
          "402": {
            "description": "Cuota insuficiente, se requiere recarga",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                },
                "example": {
                  "error": {
                    "code": 402,
                    "message": "Cuota insuficiente",
                    "type": "insufficient_quota_error"
                  }
                }
              }
            }
          },
          "403": {
            "description": "Acceso denegado",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                },
                "example": {
                  "error": {
                    "code": 403,
                    "message": "Access denied for this model",
                    "type": "permission_error",
                    "param": "model"
                  }
                }
              }
            }
          },
          "404": {
            "description": "Recurso no encontrado",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                },
                "example": {
                  "error": {
                    "code": 404,
                    "message": "Specified model not found",
                    "type": "not_found_error",
                    "param": "model"
                  }
                }
              }
            }
          },
          "413": {
            "description": "Cuerpo de solicitud demasiado grande",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                },
                "example": {
                  "error": {
                    "code": 413,
                    "message": "Cuerpo de solicitud demasiado grande",
                    "type": "request_too_large_error",
                    "param": "messages"
                  }
                }
              }
            }
          },
          "429": {
            "description": "Semilla aleatoria, rango `[1, 2147483647]`\n\n**Nota:**\n- Usar el mismo valor de semilla puede mantener resultados de generación consistentes\n- Dejar vacío para semilla aleatoria",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                },
                "example": {
                  "error": {
                    "code": 429,
                    "message": "Semilla aleatoria, rango `[1, 2147483647]`\n\n**Nota:**\n- Usar el mismo valor de semilla puede mantener resultados de generación consistentes\n- Dejar vacío para semilla aleatoria",
                    "type": "rate_limit_error"
                  }
                }
              }
            }
          },
          "500": {
            "description": "Error interno del servidor",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                },
                "example": {
                  "error": {
                    "code": 500,
                    "message": "Error interno del servidor",
                    "type": "internal_server_error"
                  }
                }
              }
            }
          },
          "502": {
            "description": "Error del servicio upstream",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                },
                "example": {
                  "error": {
                    "code": 502,
                    "message": "Upstream AI service unavailable",
                    "type": "upstream_error"
                  }
                }
              }
            }
          },
          "503": {
            "description": "Servicio temporalmente no disponible",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                },
                "example": {
                  "error": {
                    "code": 503,
                    "message": "Servicio temporalmente no disponible",
                    "type": "service_unavailable_error"
                  }
                }
              }
            }
          }
        }
      }
    }
  },
  "components": {
    "schemas": {
      "ChatCompletionRequest": {
        "type": "object",
        "required": [
          "model",
          "messages"
        ],
        "properties": {
          "model": {
            "type": "string",
            "description": "Nombre del modelo de chat\n\n- `deepseek-chat`: Modelo de conversación general\n- `deepseek-reasoner`: Modelo de razonamiento profundo, destaca en matemáticas, programación y razonamiento lógico complejo\n\n**Nota**: `deepseek-reasoner` no soporta los parámetros `temperature`, `top_p`, `tools`, `tool_choice`, `response_format`. Pasarlos será rechazado por el upstream",
            "enum": [
              "deepseek-chat",
              "deepseek-reasoner"
            ],
            "default": "deepseek-chat",
            "example": "deepseek-chat"
          },
          "messages": {
            "type": "array",
            "description": "Lista de mensajes de conversación, soporta conversación de múltiples turnos\n\nDiferentes roles tienen diferentes estructuras de campos, selecciona el rol correspondiente para ver",
            "items": {
              "oneOf": [
                {
                  "$ref": "#/components/schemas/SystemMessage"
                },
                {
                  "$ref": "#/components/schemas/UserMessage"
                },
                {
                  "$ref": "#/components/schemas/AssistantRequestMessage"
                },
                {
                  "$ref": "#/components/schemas/ToolMessage"
                }
              ],
              "discriminator": {
                "propertyName": "role",
                "mapping": {
                  "system": "#/components/schemas/SystemMessage",
                  "user": "#/components/schemas/UserMessage",
                  "assistant": "#/components/schemas/AssistantRequestMessage",
                  "tool": "#/components/schemas/ToolMessage"
                }
              }
            },
            "minItems": 1
          },
          "thinking": {
            "type": "object",
            "description": "Control del modo de pensamiento (Beta)\n\n**Detalles**:\n- Controla la función de pensamiento profundo del modelo `deepseek-reasoner`\n- Cuando está habilitado, el modelo realizará un razonamiento profundo antes de responder",
            "properties": {
              "type": {
                "type": "string",
                "description": "Interruptor del modo de pensamiento\n\n- `enabled`: Habilitar pensamiento profundo\n- `disabled`: Deshabilitar pensamiento profundo",
                "enum": [
                  "enabled",
                  "disabled"
                ]
              }
            }
          },
          "frequency_penalty": {
            "type": "number",
            "description": "Penalización de frecuencia, número entre -2.0 y 2.0\n\n**Nota**:\n- Los valores positivos penalizan los nuevos tokens según su frecuencia en el texto, disminuyendo la probabilidad de repetir las mismas frases textualmente",
            "minimum": -2,
            "maximum": 2,
            "default": 0,
            "example": 0
          },
          "max_tokens": {
            "type": "integer",
            "description": "Número máximo de tokens a generar\n\n**Detalles**:\n- El modelo dejará de generar cuando se alcance este límite\n- Si no se establece, el modelo decide la longitud de generación",
            "minimum": 1,
            "example": 4096
          },
          "presence_penalty": {
            "type": "number",
            "description": "Parámetro de penalización de presencia para fomentar nuevos temas\n\n**Detalles**:\n- Los valores positivos penalizan tokens según si han aparecido en el texto\n- Valores más altos fomentan discutir nuevos temas\n- Predeterminado: 0 (sin penalización)",
            "minimum": -2,
            "maximum": 2,
            "default": 0,
            "example": 0
          },
          "response_format": {
            "type": "object",
            "description": "Especificar formato de respuesta\n\n**Detalles**:\n- Establezca `{\"type\": \"json_object\"}` para habilitar el modo JSON\n- En modo JSON, el modelo generará contenido JSON válido",
            "properties": {
              "type": {
                "type": "string",
                "enum": [
                  "text",
                  "json_object"
                ],
                "description": "Tipo de formato de respuesta",
                "default": "text"
              }
            }
          },
          "stop": {
            "description": "Secuencias de parada. El modelo dejará de generar al encontrar estas cadenas\n\n**Detalles**:\n- Puede ser una cadena única o un arreglo de cadenas\n- Máximo 16 secuencias de parada",
            "oneOf": [
              {
                "type": "string"
              },
              {
                "type": "array",
                "items": {
                  "type": "string"
                },
                "maxItems": 16
              }
            ]
          },
          "stream": {
            "type": "boolean",
            "description": "Si transmitir la respuesta en streaming\n\n- `true`: Streaming vía SSE (Server-Sent Events), devolviendo contenido en fragmentos en tiempo real\n- `false`: Esperar la respuesta completa antes de devolver",
            "default": false,
            "example": false
          },
          "stream_options": {
            "type": "object",
            "description": "Opciones de respuesta en streaming\n\nSolo es efectivo cuando `stream=true`",
            "properties": {
              "include_usage": {
                "type": "boolean",
                "description": "Devolver estadísticas de uso al final del stream"
              }
            }
          },
          "temperature": {
            "type": "number",
            "description": "Temperatura de muestreo, controla la aleatoriedad de la salida\n\n**Detalles**:\n- Valores más bajos (ej. 0.2): Salida más determinista y enfocada\n- Valores más altos (ej. 1.5): Salida más aleatoria y creativa\n- Valor predeterminado: 1",
            "minimum": 0,
            "maximum": 2,
            "default": 1,
            "example": 1
          },
          "top_p": {
            "type": "number",
            "description": "Parámetro de muestreo Nucleus\n\n**Detalles**:\n- Controla el muestreo de tokens cuya probabilidad acumulativa alcanza el umbral\n- Por ejemplo, 0.9 significa muestrear de tokens que alcanzan el 90% de probabilidad acumulativa\n- Predeterminado: 1.0 (considerar todos los tokens)\n\n**Consejo**: Evite ajustar tanto temperature como top_p simultáneamente",
            "minimum": 0,
            "maximum": 1,
            "default": 1,
            "example": 1
          },
          "tools": {
            "type": "array",
            "description": "Lista de definiciones de herramientas para Function Calling\n\n**Detalles**:\n- Máximo 128 definiciones de herramientas\n- Cada herramienta requiere un nombre, descripción y esquema de parámetros",
            "items": {
              "$ref": "#/components/schemas/Tool"
            },
            "maxItems": 128
          },
          "tool_choice": {
            "description": "Controla el comportamiento de llamada de herramientas\n\n**Opciones**:\n- `none`: No llamar a ninguna herramienta\n- `auto`: El modelo decide si llamar a herramientas\n- `required`: Forzar al modelo a llamar una o más herramientas\n\n**Por defecto**: `none` cuando no se proporcionan herramientas, `auto` cuando se proporcionan herramientas",
            "oneOf": [
              {
                "type": "string",
                "enum": [
                  "none",
                  "auto",
                  "required"
                ]
              },
              {
                "type": "object",
                "description": "Especificar una herramienta particular a llamar",
                "properties": {
                  "type": {
                    "type": "string",
                    "enum": [
                      "function"
                    ]
                  },
                  "function": {
                    "type": "object",
                    "properties": {
                      "name": {
                        "type": "string",
                        "description": "Nombre de la función a llamar"
                      }
                    },
                    "required": [
                      "name"
                    ]
                  }
                }
              }
            ]
          },
          "logprobs": {
            "type": "boolean",
            "description": "Si devolver las probabilidades logarítmicas de los tokens\n\n**Detalles**:\n- Cuando se establece en `true`, la respuesta incluirá información de probabilidad logarítmica para cada token",
            "default": false
          },
          "top_logprobs": {
            "type": "integer",
            "description": "Devolver las probabilidades logarítmicas de los N tokens más probables\n\n**Detalles**:\n- Requiere que `logprobs` esté establecido en `true`\n- Rango: `[0, 20]`",
            "minimum": 0,
            "maximum": 20
          }
        }
      },
      "SystemMessage": {
        "title": "Mensaje del sistema",
        "type": "object",
        "required": [
          "role",
          "content"
        ],
        "properties": {
          "role": {
            "type": "string",
            "enum": [
              "system"
            ],
            "description": "Identificador de rol, fijo como `system`"
          },
          "content": {
            "type": "string",
            "description": "Contenido del prompt del sistema, utilizado para definir el rol y comportamiento de la IA"
          },
          "name": {
            "type": "string",
            "description": "Nombre del participante, utilizado para distinguir diferentes fuentes de prompt del sistema"
          }
        }
      },
      "UserMessage": {
        "title": "Mensaje del usuario",
        "type": "object",
        "required": [
          "role",
          "content"
        ],
        "properties": {
          "role": {
            "type": "string",
            "enum": [
              "user"
            ],
            "description": "Identificador de rol, fijo como `user`"
          },
          "content": {
            "type": "string",
            "description": "Contenido del mensaje del usuario (cadena de texto plano)"
          },
          "name": {
            "type": "string",
            "description": "Nombre del participante, utilizado para distinguir diferentes usuarios"
          }
        }
      },
      "AssistantRequestMessage": {
        "title": "Mensaje del asistente",
        "type": "object",
        "required": [
          "role",
          "content"
        ],
        "properties": {
          "role": {
            "type": "string",
            "enum": [
              "assistant"
            ],
            "description": "Identificador de rol, fijo como `assistant`"
          },
          "content": {
            "type": [
              "string",
              "null"
            ],
            "description": "Contenido del mensaje del asistente\n\n**Detalles**:\n- Se usa para pasar respuestas históricas del asistente en conversaciones de múltiples turnos\n- Puede ser `null` cuando `tool_calls` está presente"
          },
          "name": {
            "type": "string",
            "description": "Nombre del participante"
          },
          "prefix": {
            "type": "boolean",
            "description": "Habilitar modo de continuación de prefijo (Beta)\n\n**Detalles**:\n- Solo en el último mensaje\n- Cuando es `true`, el modelo continúa generando desde el `content` de este mensaje como prefijo",
            "default": false
          },
          "reasoning_content": {
            "type": [
              "string",
              "null"
            ],
            "description": "Contenido de cadena de pensamiento (Beta)\n\n**Detalles**:\n- Solo efectivo cuando se usa el modelo `deepseek-reasoner`\n- Se usa para pasar el proceso de razonamiento histórico en conversaciones de múltiples turnos\n- Requiere que `prefix` esté establecido en `true`"
          },
          "tool_calls": {
            "type": "array",
            "description": "Lista de llamadas de herramientas\n\nUtilizado para pasar información histórica de llamadas de herramientas en conversaciones de múltiples turnos",
            "items": {
              "type": "object",
              "properties": {
                "id": {
                  "type": "string",
                  "description": "Identificador único para la llamada de herramienta"
                },
                "type": {
                  "type": "string",
                  "enum": [
                    "function"
                  ]
                },
                "function": {
                  "type": "object",
                  "properties": {
                    "name": {
                      "type": "string",
                      "description": "Nombre de la función llamada"
                    },
                    "arguments": {
                      "type": "string",
                      "description": "Descripción de la función"
                    }
                  }
                }
              }
            }
          }
        }
      },
      "ToolMessage": {
        "title": "Mensaje de herramienta",
        "type": "object",
        "required": [
          "role",
          "content",
          "tool_call_id"
        ],
        "properties": {
          "role": {
            "type": "string",
            "enum": [
              "tool"
            ],
            "description": "Identificador de rol, fijo como `tool`"
          },
          "content": {
            "type": "string",
            "description": "Contenido del resultado de la llamada de herramienta"
          },
          "tool_call_id": {
            "type": "string",
            "description": "ID de llamada de herramienta\n\nCorresponde al campo `id` devuelto en `tool_calls` del mensaje del asistente"
          }
        }
      },
      "Tool": {
        "type": "object",
        "required": [
          "type",
          "function"
        ],
        "properties": {
          "type": {
            "type": "string",
            "enum": [
              "function"
            ],
            "description": "Tipo de herramienta, actualmente solo se admite `function`"
          },
          "function": {
            "type": "object",
            "required": [
              "name"
            ],
            "properties": {
              "name": {
                "type": "string",
                "description": "Nombre de la función a llamar\n\n**Detalles**:\n- Debe consistir en caracteres a-z, A-Z, 0-9, o contener guiones bajos y guiones\n- Longitud máxima de 64 caracteres"
              },
              "description": {
                "type": "string",
                "description": "Parámetros de entrada de la función, descritos como un objeto JSON Schema\n\n**Detalles**:\n- Omitir `parameters` define una función con una lista de parámetros vacía"
              },
              "parameters": {
                "type": "object",
                "description": "Nombre de la función"
              },
              "strict": {
                "type": "boolean",
                "description": "Habilitar modo estricto (Beta)\n\n**Detalles**:\n- Cuando se establece en `true`, la API usará modo estricto para las llamadas de función\n- Asegura que la salida siempre se ajuste a la definición del JSON Schema de la función",
                "default": false
              }
            }
          }
        }
      },
      "ChatCompletionResponse": {
        "type": "object",
        "properties": {
          "id": {
            "type": "string",
            "description": "Identificador único para la completación de chat",
            "example": "930c60df-bf64-41c9-a88e-3ec75f81e00e"
          },
          "model": {
            "type": "string",
            "description": "Nombre del modelo real utilizado",
            "example": "deepseek-chat"
          },
          "object": {
            "type": "string",
            "enum": [
              "chat.completion"
            ],
            "description": "Tipo de respuesta",
            "example": "chat.completion"
          },
          "created": {
            "type": "integer",
            "description": "Marca de tiempo de creación",
            "example": 1770617860
          },
          "choices": {
            "type": "array",
            "description": "Lista de opciones de completado de chat",
            "items": {
              "$ref": "#/components/schemas/Choice"
            }
          },
          "usage": {
            "$ref": "#/components/schemas/Usage"
          },
          "system_fingerprint": {
            "type": "string",
            "description": "Identificador de huella digital del sistema",
            "example": "fp_eaab8d114b_prod0820_fp8_kvcache"
          }
        }
      },
      "Choice": {
        "type": "object",
        "properties": {
          "index": {
            "type": "integer",
            "description": "Índice de elección",
            "example": 0
          },
          "message": {
            "$ref": "#/components/schemas/AssistantMessage"
          },
          "finish_reason": {
            "type": "string",
            "description": "Razón de finalización (solo incluida en el último fragmento)",
            "enum": [
              "stop",
              "length",
              "content_filter",
              "tool_calls",
              "insufficient_system_resource"
            ],
            "example": "stop"
          }
        }
      },
      "AssistantMessage": {
        "type": "object",
        "properties": {
          "role": {
            "type": "string",
            "description": "Rol del remitente del mensaje",
            "enum": [
              "assistant"
            ],
            "example": "assistant"
          },
          "content": {
            "type": "string",
            "description": "Contenido de respuesta de la IA",
            "example": "Hello! I'm DeepSeek, a powerful AI assistant. I excel at general conversation, code generation, mathematical reasoning and many other tasks."
          },
          "reasoning_content": {
            "type": "string",
            "description": "Contenido de razonamiento (solo disponible para modelos thinking)",
            "example": "Let me analyze this problem..."
          },
          "tool_calls": {
            "type": "array",
            "description": "Lista de llamadas de herramientas (devuelta cuando el modelo decide llamar a una herramienta)",
            "items": {
              "type": "object",
              "properties": {
                "id": {
                  "type": "string",
                  "description": "Identificador único para la llamada de herramienta"
                },
                "type": {
                  "type": "string",
                  "enum": [
                    "function"
                  ]
                },
                "function": {
                  "type": "object",
                  "properties": {
                    "name": {
                      "type": "string",
                      "description": "Nombre de la función llamada"
                    },
                    "arguments": {
                      "type": "string",
                      "description": "Descripción de la función"
                    }
                  }
                }
              }
            }
          }
        }
      },
      "Usage": {
        "type": "object",
        "description": "Estadísticas de uso de tokens",
        "properties": {
          "prompt_tokens": {
            "type": "integer",
            "description": "Número de tokens en la entrada",
            "example": 16
          },
          "completion_tokens": {
            "type": "integer",
            "description": "Número de tokens en la salida",
            "example": 10
          },
          "total_tokens": {
            "type": "integer",
            "description": "Número total de tokens",
            "example": 26
          },
          "prompt_cache_hit_tokens": {
            "type": "integer",
            "description": "Número de tokens de entrada con acierto de caché",
            "example": 0
          },
          "prompt_cache_miss_tokens": {
            "type": "integer",
            "description": "Número de tokens de entrada sin acierto de caché",
            "example": 16
          }
        }
      },
      "ErrorResponse": {
        "type": "object",
        "properties": {
          "error": {
            "type": "object",
            "properties": {
              "code": {
                "type": "integer",
                "description": "Código de error de estado HTTP"
              },
              "message": {
                "type": "string",
                "description": "Mensaje de descripción del error"
              },
              "type": {
                "type": "string",
                "description": "Tiempo estimado de finalización (segundos)"
              },
              "param": {
                "type": "string",
                "description": "Nombre del parámetro relacionado"
              }
            }
          }
        }
      }
    },
    "securitySchemes": {
      "bearerAuth": {
        "type": "http",
        "scheme": "bearer",
        "description": "##Todas las APIs requieren autenticación Bearer Token##\n\n**Obtener API Key:**\n\nVisita la [Página de gestión de API Key](https://evolink.ai/dashboard/keys) para obtener tu API Key\n\n**Agregar al encabezado de la solicitud:**\n```\nAuthorization: Bearer YOUR_API_KEY\n```"
      }
    }
  },
  "tags": [
    {
      "name": "Completado de chat",
      "description": "APIs relacionadas con completado de chat IA"
    }
  ]
}