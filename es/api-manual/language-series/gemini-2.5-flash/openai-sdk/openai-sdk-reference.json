{
  "openapi": "3.1.0",
  "info": {
    "title": "gemini-2.5-flash Referencia completa",
    "description": "Referencia completa de la API para la interfaz de chat de gemini-2.5-flash, incluyendo todos los parámetros y funciones avanzadas",
    "license": {
      "name": "MIT"
    },
    "version": "1.0.0"
  },
  "servers": [
    {
      "url": "https://api.evolink.ai",
      "description": "Entorno de producción"
    }
  ],
  "security": [
    {
      "bearerAuth": []
    }
  ],
  "paths": {
    "/v1/chat/completions": {
      "post": {
        "summary": "API de Chat gemini-2.5-flash",
        "description": "- Llamar al modelo gemini-2.5-flash usando el formato del SDK de OpenAI\n- Modo de procesamiento síncrono, devuelve el contenido de la conversación en tiempo real\n- **Conversación de texto plano**: Diálogo de un solo turno o múltiples turnos con contexto, ver ejemplos simple_text y multi_turn en las muestras de código\n- **Prompt del sistema**: Personalizar el rol y comportamiento de la IA, ver ejemplo system_prompt en las muestras de código\n- **Entrada multimodal**: Soporta entrada mixta de texto + imagen, ver ejemplos vision y multi_image en las muestras de código",
        "operationId": "createChatCompletion",
        "tags": [
          "Completado de chat"
        ],
        "requestBody": {
          "required": true,
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/ChatCompletionRequest"
              },
              "examples": {
                "simple_text": {
                  "summary": "Conversación de texto de un solo turno",
                  "value": {
                    "model": "gemini-2.5-flash",
                    "messages": [
                      {
                        "role": "user",
                        "content": "Please introduce yourself"
                      }
                    ]
                  }
                },
                "multi_turn": {
                  "summary": "Conversación multi-turno (comprensión de contexto)",
                  "value": {
                    "model": "gemini-2.5-flash",
                    "messages": [
                      {
                        "role": "user",
                        "content": "What is Python?"
                      },
                      {
                        "role": "assistant",
                        "content": "Python is a high-level programming language..."
                      },
                      {
                        "role": "user",
                        "content": "What are its advantages?"
                      }
                    ]
                  }
                },
                "system_prompt": {
                  "summary": "Usando prompt del sistema",
                  "value": {
                    "model": "gemini-2.5-flash",
                    "messages": [
                      {
                        "role": "system",
                        "content": "You are a professional Python programming assistant, answering questions concisely."
                      },
                      {
                        "role": "user",
                        "content": "How to read a file?"
                      }
                    ]
                  }
                },
                "vision": {
                  "summary": "Entrada multimodal (texto + imagen)",
                  "value": {
                    "model": "gemini-2.5-flash",
                    "messages": [
                      {
                        "role": "user",
                        "content": [
                          {
                            "type": "text",
                            "text": "Please describe the scene and main elements in this image in detail."
                          },
                          {
                            "type": "image_url",
                            "image_url": {
                              "url": "https://example.com/image.png"
                            }
                          }
                        ]
                      }
                    ]
                  }
                },
                "multi_image": {
                  "summary": "Entrada de múltiples imágenes",
                  "value": {
                    "model": "gemini-2.5-flash",
                    "messages": [
                      {
                        "role": "user",
                        "content": [
                          {
                            "type": "text",
                            "text": "Compare the differences between these two images"
                          },
                          {
                            "type": "image_url",
                            "image_url": {
                              "url": "https://example.com/image1.png"
                            }
                          },
                          {
                            "type": "image_url",
                            "image_url": {
                              "url": "https://example.com/image2.png"
                            }
                          }
                        ]
                      }
                    ]
                  }
                }
              }
            }
          }
        },
        "responses": {
          "200": {
            "description": "Completado de chat generado exitosamente",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ChatCompletionResponse"
                }
              }
            }
          },
          "400": {
            "description": "Parámetros de solicitud inválidos",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                },
                "example": {
                  "error": {
                    "code": 400,
                    "message": "Parámetros de solicitud inválidos",
                    "type": "invalid_request_error"
                  }
                }
              }
            }
          },
          "401": {
            "description": "No autorizado, token inválido o expirado",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                },
                "example": {
                  "error": {
                    "code": 401,
                    "message": "Invalid or expired token",
                    "type": "authentication_error"
                  }
                }
              }
            }
          },
          "402": {
            "description": "Cuota insuficiente, se requiere recarga",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                },
                "example": {
                  "error": {
                    "code": 402,
                    "message": "Cuota insuficiente",
                    "type": "insufficient_quota_error",
                    "fallback_suggestion": "https://evolink.ai/dashboard/billing"
                  }
                }
              }
            }
          },
          "403": {
            "description": "Acceso denegado",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                },
                "example": {
                  "error": {
                    "code": 403,
                    "message": "Access denied for this model",
                    "type": "permission_error",
                    "param": "model"
                  }
                }
              }
            }
          },
          "404": {
            "description": "Recurso no encontrado",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                },
                "example": {
                  "error": {
                    "code": 404,
                    "message": "Specified model not found",
                    "type": "not_found_error",
                    "param": "model",
                    "fallback_suggestion": "gemini-2.5-flash"
                  }
                }
              }
            }
          },
          "413": {
            "description": "Cuerpo de solicitud demasiado grande",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                },
                "example": {
                  "error": {
                    "code": 413,
                    "message": "Image file too large",
                    "type": "request_too_large_error",
                    "param": "content",
                    "fallback_suggestion": "compress image to under 10MB"
                  }
                }
              }
            }
          },
          "429": {
            "description": "Semilla aleatoria, rango `[1, 2147483647]`\n\n**Nota:**\n- Usar el mismo valor de semilla puede mantener resultados de generación consistentes\n- Dejar vacío para semilla aleatoria",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                },
                "example": {
                  "error": {
                    "code": 429,
                    "message": "Semilla aleatoria, rango `[1, 2147483647]`\n\n**Nota:**\n- Usar el mismo valor de semilla puede mantener resultados de generación consistentes\n- Dejar vacío para semilla aleatoria",
                    "type": "rate_limit_error",
                    "fallback_suggestion": "retry after 60 seconds"
                  }
                }
              }
            }
          },
          "500": {
            "description": "Error interno del servidor",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                },
                "example": {
                  "error": {
                    "code": 500,
                    "message": "Error interno del servidor",
                    "type": "internal_server_error",
                    "fallback_suggestion": "try again later"
                  }
                }
              }
            }
          },
          "502": {
            "description": "Error del servicio upstream",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                },
                "example": {
                  "error": {
                    "code": 502,
                    "message": "Upstream AI service unavailable",
                    "type": "upstream_error",
                    "fallback_suggestion": "try different model"
                  }
                }
              }
            }
          },
          "503": {
            "description": "Servicio temporalmente no disponible",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                },
                "example": {
                  "error": {
                    "code": 503,
                    "message": "Servicio temporalmente no disponible",
                    "type": "service_unavailable_error",
                    "fallback_suggestion": "retry after 30 seconds"
                  }
                }
              }
            }
          }
        }
      }
    }
  },
  "components": {
    "schemas": {
      "ChatCompletionRequest": {
        "type": "object",
        "required": [
          "model",
          "messages"
        ],
        "properties": {
          "model": {
            "type": "string",
            "description": "Nombre del modelo de chat",
            "enum": [
              "gemini-2.5-flash"
            ],
            "default": "gemini-2.5-flash",
            "example": "gemini-2.5-flash"
          },
          "messages": {
            "type": "array",
            "description": "Lista de mensajes de chat, soporta diálogo de múltiples turnos y entrada multimodal",
            "items": {
              "$ref": "#/components/schemas/Message"
            },
            "minItems": 1
          },
          "stream": {
            "type": "boolean",
            "description": "Si se devuelve la respuesta en modo streaming\n\n- `true`: Retorno en streaming, recibe contenido en fragmentos en tiempo real\n- `false`: Devuelve la respuesta completa de una sola vez",
            "example": false
          },
          "max_tokens": {
            "type": "integer",
            "description": "Número máximo de tokens para la respuesta generada\n\n**Descripción**:\n- Un valor demasiado pequeño puede causar truncamiento de la respuesta",
            "minimum": 1,
            "example": 2000
          },
          "temperature": {
            "type": "number",
            "description": "Temperatura de muestreo, controla la aleatoriedad de la salida\n\n**Descripción**:\n- Valores más bajos (ej., 0.2): Salida más determinista y enfocada\n- Valores más altos (ej., 1.5): Salida más aleatoria y creativa",
            "minimum": 0,
            "maximum": 2,
            "example": 0.7
          },
          "top_p": {
            "type": "number",
            "description": "Parámetro de Nucleus Sampling\n\n**Descripción**:\n- Controla el muestreo de tokens con probabilidad acumulada\n- Por ejemplo, 0.9 significa seleccionar entre tokens con probabilidad acumulada de hasta el 90%\n- Valor predeterminado: 1.0 (considera todos los tokens)\n\n**Recomendación**: No ajustar temperature y top_p simultáneamente",
            "minimum": 0,
            "maximum": 1,
            "example": 0.9
          },
          "top_k": {
            "type": "integer",
            "description": "Parámetro de muestreo Top-K\n\n**Descripción**:\n- Por ejemplo, 10 significa limitar el muestreo a considerar solo los 10 tokens más probables\n- Valores más pequeños hacen la salida más enfocada\n- Predeterminado: sin límite",
            "minimum": 1,
            "example": 40
          }
        }
      },
      "Message": {
        "type": "object",
        "required": [
          "role",
          "content"
        ],
        "properties": {
          "role": {
            "type": "string",
            "description": "Rol del mensaje\n\n- `user`: Mensaje del usuario\n- `assistant`: Mensaje del asistente de IA (para conversación de múltiples turnos)\n- `system`: Prompt del sistema (establece el rol y comportamiento de la IA)",
            "enum": [
              "user",
              "assistant",
              "system"
            ],
            "example": "user"
          },
          "content": {
            "type": "array",
            "description": "Contenido del mensaje. Soporta dos formatos:\n\n**1. Cadena de texto plano**: Se puede pasar directamente una cadena, por ejemplo, `\"content\":\"Por favor preséntate\"`\n\n**2. Array de objetos** (soporta entrada de texto, entrada multimodal): Ver estructura de ejemplo a continuación",
            "items": {
              "$ref": "#/components/schemas/ContentPart"
            }
          }
        }
      },
      "ContentPart": {
        "oneOf": [
          {
            "$ref": "#/components/schemas/TextContent"
          },
          {
            "$ref": "#/components/schemas/ImageContent"
          }
        ]
      },
      "TextContent": {
        "title": "Contenido de texto",
        "type": "object",
        "required": [
          "type",
          "text"
        ],
        "properties": {
          "type": {
            "type": "string",
            "enum": [
              "text"
            ],
            "description": "Tipo de contenido"
          },
          "text": {
            "type": "string",
            "description": "Contenido de texto",
            "example": "Please describe this image in detail"
          }
        }
      },
      "ImageContent": {
        "title": "Contenido de imagen",
        "type": "object",
        "required": [
          "type",
          "image_url"
        ],
        "properties": {
          "type": {
            "type": "string",
            "enum": [
              "image_url"
            ],
            "description": "Tipo de contenido"
          },
          "image_url": {
            "type": "object",
            "required": [
              "url"
            ],
            "properties": {
              "url": {
                "type": "string",
                "format": "uri",
                "description": "Dirección URL de la imagen\n\n**Límites**:\n- Tamaño máximo por imagen: `10MB`\n- Formatos soportados: `.jpeg`, `.jpg`, `.png`, `.webp`\n- Requisitos de URL: Debe ser accesible públicamente, generalmente termina con extensión de imagen",
                "example": "https://example.com/image.png"
              }
            }
          }
        }
      },
      "ChatCompletionResponse": {
        "type": "object",
        "properties": {
          "id": {
            "type": "string",
            "description": "Identificador único para la completación de chat",
            "example": "chatcmpl-20251010015944503180122WJNB8Eid"
          },
          "model": {
            "type": "string",
            "description": "Nombre del modelo realmente utilizado",
            "example": "gemini-2.5-flash"
          },
          "object": {
            "type": "string",
            "enum": [
              "chat.completion"
            ],
            "description": "Tipo de respuesta",
            "example": "chat.completion"
          },
          "created": {
            "type": "integer",
            "description": "Marca de tiempo de creación",
            "example": 1760032810
          },
          "choices": {
            "type": "array",
            "description": "Lista de opciones de completado de chat",
            "items": {
              "$ref": "#/components/schemas/Choice"
            }
          },
          "usage": {
            "$ref": "#/components/schemas/Usage"
          }
        }
      },
      "Choice": {
        "type": "object",
        "properties": {
          "index": {
            "type": "integer",
            "description": "Índice de elección",
            "example": 0
          },
          "message": {
            "$ref": "#/components/schemas/AssistantMessage"
          },
          "finish_reason": {
            "type": "string",
            "description": "Razón de finalización\n\n- `stop`: Finalización natural o secuencia de parada alcanzada\n- `length`: Límite máximo de tokens alcanzado\n- `content_filter`: Salida filtrada por política de seguridad\n- `tool_calls`: El modelo llamó a una herramienta\n- `insufficient_system_resource`: Restricciones de recursos del backend",
            "enum": [
              "stop",
              "length",
              "content_filter"
            ],
            "example": "stop"
          }
        }
      },
      "AssistantMessage": {
        "type": "object",
        "properties": {
          "role": {
            "type": "string",
            "description": "Rol del remitente del mensaje",
            "enum": [
              "assistant"
            ],
            "example": "assistant"
          },
          "content": {
            "type": "string",
            "description": "Contenido del mensaje de respuesta de la IA",
            "example": "Hello! I'm pleased to introduce myself.\n\nI'm a Large Language Model, trained and developed by Google.\n\nSimply put, you can think of me as a \"smart brain\" that has been trained on massive amounts of text data and is able to understand and generate human language. My core capability is processing and generating text. Specifically, I can do the following:\n\n**1. Information Query & Knowledge Answering**\nI can act like a \"talking encyclopedia,\" answering various questions, whether they're about scientific knowledge, historical events, or everyday facts.\n\n**2. Creative Writing & Text Generation**\nI can create various types of text based on your requirements, such as:\n*   **Writing**: Poetry, stories, scripts, emails, speeches, advertising copy, etc.\n*   **Planning**: Travel plans, study outlines, event proposals, etc.\n*   **Brainstorming**: Working with you to generate new ideas and spark creativity.\n\n**3. Translation & Language Processing**\nI'm proficient in multiple languages and can provide fast, fluent translation services. I can also help you polish, proofread, summarize, or rewrite text to make your expression clearer and more professional.\n\n**4. Programming & Code Assistance**\nI can write code snippets, explain code logic, debug errors, or \"translate\" code from one programming language to another, making me a helpful companion for programmers.\n\n**5. Logical Analysis & Reasoning**\nI can help you analyze complex problems, organize logical chains, and make inferences and summaries based on the information you provide.\n\n---\n\n**In summary**, my goal is to be a powerful and useful tool that helps you obtain information more efficiently, complete tasks, and spark creativity through natural language communication.\n\n**Remember:** I'm an artificial intelligence, my knowledge comes from the data I've learned, and it may not be the most up-to-date. Sometimes I may also make mistakes, so for very important information, I recommend you verify it again."
          }
        }
      },
      "Usage": {
        "type": "object",
        "description": "Estadísticas de uso de tokens",
        "properties": {
          "prompt_tokens": {
            "type": "integer",
            "description": "Número de tokens en el contenido de entrada",
            "example": 13
          },
          "completion_tokens": {
            "type": "integer",
            "description": "Número de tokens en el contenido de salida",
            "example": 1891
          },
          "total_tokens": {
            "type": "integer",
            "description": "Número total de tokens",
            "example": 1904
          },
          "prompt_tokens_details": {
            "type": "object",
            "description": "Información detallada de tokens de entrada",
            "properties": {
              "cached_tokens": {
                "type": "integer",
                "description": "Número de tokens en caché alcanzados",
                "example": 0
              },
              "text_tokens": {
                "type": "integer",
                "description": "Número de tokens de texto",
                "example": 13
              },
              "audio_tokens": {
                "type": "integer",
                "description": "Número de tokens de audio",
                "example": 0
              },
              "image_tokens": {
                "type": "integer",
                "description": "Número de tokens de imagen",
                "example": 0
              }
            }
          },
          "completion_tokens_details": {
            "type": "object",
            "description": "Información detallada de tokens de salida",
            "properties": {
              "text_tokens": {
                "type": "integer",
                "description": "Número de tokens de texto",
                "example": 0
              },
              "audio_tokens": {
                "type": "integer",
                "description": "Número de tokens de audio",
                "example": 0
              },
              "reasoning_tokens": {
                "type": "integer",
                "description": "Número de tokens de razonamiento",
                "example": 1480
              }
            }
          },
          "input_tokens": {
            "type": "integer",
            "description": "Número de tokens de entrada (campo de compatibilidad)",
            "example": 0
          },
          "output_tokens": {
            "type": "integer",
            "description": "Número de tokens de salida (campo de compatibilidad)",
            "example": 0
          },
          "input_tokens_details": {
            "type": "object",
            "nullable": true,
            "description": "Información detallada de tokens de entrada (campo de compatibilidad)",
            "example": null
          }
        }
      },
      "ErrorResponse": {
        "type": "object",
        "properties": {
          "error": {
            "type": "object",
            "properties": {
              "code": {
                "type": "integer",
                "description": "Código de error de estado HTTP"
              },
              "message": {
                "type": "string",
                "description": "Mensaje de descripción del error"
              },
              "type": {
                "type": "string",
                "description": "Tiempo estimado de finalización (segundos)"
              },
              "param": {
                "type": "string",
                "description": "Nombre del parámetro relacionado"
              },
              "fallback_suggestion": {
                "type": "string",
                "description": "Sugerencia cuando ocurre un error"
              }
            }
          }
        }
      }
    },
    "securitySchemes": {
      "bearerAuth": {
        "type": "http",
        "scheme": "bearer",
        "description": "##Todas las APIs requieren autenticación Bearer Token##\n\n**Obtener API Key:**\n\nVisita la [Página de gestión de API Key](https://evolink.ai/dashboard/keys) para obtener tu API Key\n\n**Agregar al encabezado de la solicitud:**\n```\nAuthorization: Bearer YOUR_API_KEY\n```"
      }
    }
  },
  "tags": [
    {
      "name": "Completado de chat",
      "description": "APIs relacionadas con completado de chat IA"
    }
  ]
}