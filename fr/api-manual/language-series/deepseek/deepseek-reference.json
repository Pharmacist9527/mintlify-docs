{
  "openapi": "3.1.0",
  "info": {
    "title": "Référence complète de l'API DeepSeek",
    "description": "Référence API complète pour l'interface de chat DeepSeek, incluant tous les paramètres et fonctionnalités avancées",
    "license": {
      "name": "MIT"
    },
    "version": "1.0.0"
  },
  "servers": [
    {
      "url": "https://api.evolink.ai",
      "description": "Environnement de production"
    }
  ],
  "security": [
    {
      "bearerAuth": []
    }
  ],
  "paths": {
    "/v1/chat/completions": {
      "post": {
        "summary": "API de chat DeepSeek",
        "description": "- Appeler les modèles DeepSeek au format OpenAI SDK\n- Mode de traitement synchrone, réponse en temps réel\n- Prend en charge les modèles `deepseek-chat` (conversation générale) et `deepseek-reasoner` (raisonnement approfondi)\n- **Chat textuel** : Conversation contextuelle à un ou plusieurs tours\n- **Prompts système** : Personnaliser le rôle et le comportement de l'IA\n- **Streaming** : Prise en charge de la sortie en streaming SSE\n- **Appel d'outils** : Prise en charge du Function Calling",
        "operationId": "createChatCompletionDeepSeek",
        "tags": [
          "Complétion de chat"
        ],
        "requestBody": {
          "required": true,
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/ChatCompletionRequest"
              },
              "examples": {
                "simple_text": {
                  "summary": "Discussion textuelle simple",
                  "value": {
                    "model": "deepseek-chat",
                    "messages": [
                      {
                        "role": "user",
                        "content": "Tell me about yourself"
                      }
                    ]
                  }
                },
                "multi_turn": {
                  "summary": "Conversation multi-tours",
                  "value": {
                    "model": "deepseek-chat",
                    "messages": [
                      {
                        "role": "user",
                        "content": "What is Python?"
                      },
                      {
                        "role": "assistant",
                        "content": "Python is a high-level programming language..."
                      },
                      {
                        "role": "user",
                        "content": "What are its advantages?"
                      }
                    ]
                  }
                },
                "system_prompt": {
                  "summary": "Utilisation de l'invite système",
                  "value": {
                    "model": "deepseek-chat",
                    "messages": [
                      {
                        "role": "system",
                        "content": "You are a professional Python programming assistant. Answer questions concisely."
                      },
                      {
                        "role": "user",
                        "content": "How to read a file?"
                      }
                    ]
                  }
                },
                "reasoner": {
                  "summary": "Utilisation du modèle de raisonnement approfondi",
                  "value": {
                    "model": "deepseek-reasoner",
                    "messages": [
                      {
                        "role": "user",
                        "content": "Prove that the square root of 2 is irrational"
                      }
                    ]
                  }
                }
              }
            }
          }
        },
        "responses": {
          "200": {
            "description": "Complétion de chat générée avec succès",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ChatCompletionResponse"
                }
              }
            }
          },
          "400": {
            "description": "Paramètres de requête invalides",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                },
                "example": {
                  "error": {
                    "code": 400,
                    "message": "Paramètres de requête invalides",
                    "type": "invalid_request_error"
                  }
                }
              }
            }
          },
          "401": {
            "description": "Non authentifié, jeton invalide ou expiré",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                },
                "example": {
                  "error": {
                    "code": 401,
                    "message": "Invalid or expired token",
                    "type": "authentication_error"
                  }
                }
              }
            }
          },
          "402": {
            "description": "Quota insuffisant, recharge requise",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                },
                "example": {
                  "error": {
                    "code": 402,
                    "message": "Quota insuffisant",
                    "type": "insufficient_quota_error"
                  }
                }
              }
            }
          },
          "403": {
            "description": "Accès refusé",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                },
                "example": {
                  "error": {
                    "code": 403,
                    "message": "Access denied for this model",
                    "type": "permission_error",
                    "param": "model"
                  }
                }
              }
            }
          },
          "404": {
            "description": "Ressource introuvable",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                },
                "example": {
                  "error": {
                    "code": 404,
                    "message": "Specified model not found",
                    "type": "not_found_error",
                    "param": "model"
                  }
                }
              }
            }
          },
          "413": {
            "description": "Corps de la requête trop volumineux",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                },
                "example": {
                  "error": {
                    "code": 413,
                    "message": "Corps de la requête trop volumineux",
                    "type": "request_too_large_error",
                    "param": "messages"
                  }
                }
              }
            }
          },
          "429": {
            "description": "Limite de débit dépassée",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                },
                "example": {
                  "error": {
                    "code": 429,
                    "message": "Limite de débit dépassée",
                    "type": "rate_limit_error"
                  }
                }
              }
            }
          },
          "500": {
            "description": "Erreur interne du serveur",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                },
                "example": {
                  "error": {
                    "code": 500,
                    "message": "Erreur interne du serveur",
                    "type": "internal_server_error"
                  }
                }
              }
            }
          },
          "502": {
            "description": "Erreur du service en amont",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                },
                "example": {
                  "error": {
                    "code": 502,
                    "message": "Upstream AI service unavailable",
                    "type": "upstream_error"
                  }
                }
              }
            }
          },
          "503": {
            "description": "Service temporairement indisponible",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                },
                "example": {
                  "error": {
                    "code": 503,
                    "message": "Service temporairement indisponible",
                    "type": "service_unavailable_error"
                  }
                }
              }
            }
          }
        }
      }
    }
  },
  "components": {
    "schemas": {
      "ChatCompletionRequest": {
        "type": "object",
        "required": [
          "model",
          "messages"
        ],
        "properties": {
          "model": {
            "type": "string",
            "description": "Nom du modèle de chat\n\n- `deepseek-chat` : Modèle de conversation générale\n- `deepseek-reasoner` : Modèle de raisonnement profond, excelle en mathématiques, codage et raisonnement logique complexe\n\n**Remarque** : `deepseek-reasoner` ne prend pas en charge les paramètres `temperature`, `top_p`, `tools`, `tool_choice`, `response_format`. Leur transmission sera rejetée par l'amont",
            "enum": [
              "deepseek-chat",
              "deepseek-reasoner"
            ],
            "default": "deepseek-chat",
            "example": "deepseek-chat"
          },
          "messages": {
            "type": "array",
            "description": "Liste de messages de conversation, prend en charge les conversations multi-tours\n\nDifférents rôles ont différentes structures de champs, sélectionnez le rôle correspondant pour voir",
            "items": {
              "oneOf": [
                {
                  "$ref": "#/components/schemas/SystemMessage"
                },
                {
                  "$ref": "#/components/schemas/UserMessage"
                },
                {
                  "$ref": "#/components/schemas/AssistantRequestMessage"
                },
                {
                  "$ref": "#/components/schemas/ToolMessage"
                }
              ],
              "discriminator": {
                "propertyName": "role",
                "mapping": {
                  "system": "#/components/schemas/SystemMessage",
                  "user": "#/components/schemas/UserMessage",
                  "assistant": "#/components/schemas/AssistantRequestMessage",
                  "tool": "#/components/schemas/ToolMessage"
                }
              }
            },
            "minItems": 1
          },
          "thinking": {
            "type": "object",
            "description": "Contrôle du mode de réflexion (Bêta)\n\n**Détails** :\n- Contrôle la fonctionnalité de réflexion approfondie du modèle `deepseek-reasoner`\n- Lorsqu'il est activé, le modèle effectuera un raisonnement approfondi avant de répondre",
            "properties": {
              "type": {
                "type": "string",
                "description": "Commutateur de mode de réflexion\n\n- `enabled` : Activer la réflexion approfondie\n- `disabled` : Désactiver la réflexion approfondie",
                "enum": [
                  "enabled",
                  "disabled"
                ]
              }
            }
          },
          "frequency_penalty": {
            "type": "number",
            "description": "Paramètre de pénalité de fréquence pour réduire le contenu répétitif\n\n**Détails** :\n- Les valeurs positives pénalisent les tokens en fonction de leur fréquence dans le texte généré\n- Des valeurs plus élevées rendent moins probable la répétition du contenu existant\n- Par défaut : 0 (aucune pénalité)",
            "minimum": -2,
            "maximum": 2,
            "default": 0,
            "example": 0
          },
          "max_tokens": {
            "type": "integer",
            "description": "Nombre maximum de tokens à générer\n\n**Détails :**\n- Le modèle arrêtera de générer lorsque cette limite est atteinte\n- Si non défini, le modèle décide de la longueur de génération",
            "minimum": 1,
            "example": 4096
          },
          "presence_penalty": {
            "type": "number",
            "description": "Paramètre de pénalité de présence pour encourager de nouveaux sujets\n\n**Détails** :\n- Les valeurs positives pénalisent les tokens en fonction de leur apparition dans le texte\n- Des valeurs plus élevées encouragent la discussion de nouveaux sujets\n- Par défaut : 0 (aucune pénalité)",
            "minimum": -2,
            "maximum": 2,
            "default": 0,
            "example": 0
          },
          "response_format": {
            "type": "object",
            "description": "Spécifier le format de réponse\n\n**Détails** :\n- Définir sur `{\"type\": \"json_object\"}` pour activer le mode JSON\n- En mode JSON, le modèle produira un contenu JSON valide",
            "properties": {
              "type": {
                "type": "string",
                "enum": [
                  "text",
                  "json_object"
                ],
                "description": "Type de format de réponse",
                "default": "text"
              }
            }
          },
          "stop": {
            "description": "Séquences d'arrêt. Le modèle arrêtera de générer lorsqu'il rencontrera ces chaînes\n\n**Détails** :\n- Peut être une chaîne unique ou un tableau de chaînes\n- Maximum 16 séquences d'arrêt",
            "oneOf": [
              {
                "type": "string"
              },
              {
                "type": "array",
                "items": {
                  "type": "string"
                },
                "maxItems": 16
              }
            ]
          },
          "stream": {
            "type": "boolean",
            "description": "S'il faut diffuser la réponse en streaming\n\n- `true` : Streaming via SSE (Server-Sent Events), retournant le contenu en morceaux en temps réel\n- `false` : Attendre la réponse complète avant de retourner",
            "default": false,
            "example": false
          },
          "stream_options": {
            "type": "object",
            "description": "Options de réponse en streaming\n\nEffectives uniquement lorsque `stream=true`",
            "properties": {
              "include_usage": {
                "type": "boolean",
                "description": "Renvoyer les statistiques d'utilisation à la fin du flux"
              }
            }
          },
          "temperature": {
            "type": "number",
            "description": "Température d'échantillonnage, contrôle le caractère aléatoire de la sortie\n\n**Détails** :\n- Valeurs basses (ex. 0.2) : Sortie plus déterministe et ciblée\n- Valeurs élevées (ex. 1.5) : Sortie plus aléatoire et créative\n- Par défaut : 1",
            "minimum": 0,
            "maximum": 2,
            "default": 1,
            "example": 1
          },
          "top_p": {
            "type": "number",
            "description": "Paramètre de Nucleus Sampling\n\n**Détails :**\n- Contrôle l'échantillonnage à partir de tokens dont la probabilité cumulative atteint le seuil\n- Par exemple, 0.9 signifie échantillonner parmi les tokens atteignant 90% de probabilité cumulative\n- Par défaut : 1.0 (considère tous les tokens)\n\n**Conseil** : Éviter d'ajuster à la fois temperature et top_p simultanément",
            "minimum": 0,
            "maximum": 1,
            "default": 1,
            "example": 1
          },
          "tools": {
            "type": "array",
            "description": "Liste de définitions d'outils pour Function Calling\n\n**Détails** :\n- Maximum 128 définitions d'outils\n- Chaque outil nécessite un nom, une description et un schéma de paramètres",
            "items": {
              "$ref": "#/components/schemas/Tool"
            },
            "maxItems": 128
          },
          "tool_choice": {
            "description": "Contrôle le comportement d'appel d'outils\n\n**Options** :\n- `none` : N'appeler aucun outil\n- `auto` : Le modèle décide d'appeler ou non des outils\n- `required` : Forcer le modèle à appeler un ou plusieurs outils\n\n**Par défaut** : `none` si aucun outil fourni, `auto` si des outils sont fournis",
            "oneOf": [
              {
                "type": "string",
                "enum": [
                  "none",
                  "auto",
                  "required"
                ]
              },
              {
                "type": "object",
                "description": "Spécifier un outil particulier à appeler",
                "properties": {
                  "type": {
                    "type": "string",
                    "enum": [
                      "function"
                    ]
                  },
                  "function": {
                    "type": "object",
                    "properties": {
                      "name": {
                        "type": "string",
                        "description": "Nom de la fonction à appeler"
                      }
                    },
                    "required": [
                      "name"
                    ]
                  }
                }
              }
            ]
          },
          "logprobs": {
            "type": "boolean",
            "description": "S'il faut retourner les probabilités logarithmiques des tokens\n\n**Détails** :\n- Lorsque défini sur `true`, la réponse inclura les informations de probabilité logarithmique pour chaque token",
            "default": false
          },
          "top_logprobs": {
            "type": "integer",
            "description": "Renvoyer les probabilités logarithmiques des N tokens les plus probables\n\n**Détails** :\n- Nécessite que `logprobs` soit défini sur `true`\n- Plage : `[0, 20]`",
            "minimum": 0,
            "maximum": 20
          }
        }
      },
      "SystemMessage": {
        "title": "Message système",
        "type": "object",
        "required": [
          "role",
          "content"
        ],
        "properties": {
          "role": {
            "type": "string",
            "enum": [
              "system"
            ],
            "description": "Identifiant de rôle, fixé à `system`"
          },
          "content": {
            "type": "string",
            "description": "Contenu de l'invite système, utilisé pour définir le rôle et le comportement de l'IA"
          },
          "name": {
            "type": "string",
            "description": "Nom du participant, utilisé pour distinguer différentes sources d'invites système"
          }
        }
      },
      "UserMessage": {
        "title": "Message utilisateur",
        "type": "object",
        "required": [
          "role",
          "content"
        ],
        "properties": {
          "role": {
            "type": "string",
            "enum": [
              "user"
            ],
            "description": "Identifiant de rôle, fixé à `user`"
          },
          "content": {
            "type": "string",
            "description": "Contenu du message utilisateur (chaîne de texte brut)"
          },
          "name": {
            "type": "string",
            "description": "Nom du participant, utilisé pour distinguer différents utilisateurs"
          }
        }
      },
      "AssistantRequestMessage": {
        "title": "Message de l'assistant",
        "type": "object",
        "required": [
          "role",
          "content"
        ],
        "properties": {
          "role": {
            "type": "string",
            "enum": [
              "assistant"
            ],
            "description": "Identifiant de rôle, fixé à `assistant`"
          },
          "content": {
            "type": [
              "string",
              "null"
            ],
            "description": "Contenu du message de l'assistant\n\n**Détails** :\n- Utilisé pour transmettre les réponses historiques de l'assistant dans les conversations multi-tours\n- Peut être `null` lorsque `tool_calls` est présent"
          },
          "name": {
            "type": "string",
            "description": "Nom du participant"
          },
          "prefix": {
            "type": "boolean",
            "description": "Activer le mode de continuation de préfixe (Beta)\n\n**Détails** :\n- Uniquement sur le dernier message\n- Lorsque `true`, le modèle continue à générer à partir du `content` de ce message comme préfixe",
            "default": false
          },
          "reasoning_content": {
            "type": [
              "string",
              "null"
            ],
            "description": "Contenu Chain of Thought (Bêta)\n\n**Détails** :\n- Efficace uniquement avec le modèle `deepseek-reasoner`\n- Utilisé pour transmettre le processus de raisonnement historique dans les conversations multi-tours\n- Nécessite que `prefix` soit défini sur `true`"
          },
          "tool_calls": {
            "type": "array",
            "description": "Liste d'appels d'outils\n\nUtilisée pour transmettre les informations d'appels d'outils historiques dans les conversations multi-tours",
            "items": {
              "type": "object",
              "properties": {
                "id": {
                  "type": "string",
                  "description": "Identifiant unique pour l'appel d'outil"
                },
                "type": {
                  "type": "string",
                  "enum": [
                    "function"
                  ]
                },
                "function": {
                  "type": "object",
                  "properties": {
                    "name": {
                      "type": "string",
                      "description": "Nom de la fonction appelée"
                    },
                    "arguments": {
                      "type": "string",
                      "description": "Arguments de fonction (chaîne JSON)"
                    }
                  }
                }
              }
            }
          }
        }
      },
      "ToolMessage": {
        "title": "Message d'outil",
        "type": "object",
        "required": [
          "role",
          "content",
          "tool_call_id"
        ],
        "properties": {
          "role": {
            "type": "string",
            "enum": [
              "tool"
            ],
            "description": "Identifiant de rôle, fixé à `tool`"
          },
          "content": {
            "type": "string",
            "description": "Contenu du résultat d'appel d'outil"
          },
          "tool_call_id": {
            "type": "string",
            "description": "ID d'appel d'outil\n\nCorrespond au champ `id` retourné dans les `tool_calls` du message de l'assistant"
          }
        }
      },
      "Tool": {
        "type": "object",
        "required": [
          "type",
          "function"
        ],
        "properties": {
          "type": {
            "type": "string",
            "enum": [
              "function"
            ],
            "description": "Type d'outil, actuellement seul `function` est pris en charge"
          },
          "function": {
            "type": "object",
            "required": [
              "name"
            ],
            "properties": {
              "name": {
                "type": "string",
                "description": "Nom de la fonction à appeler\n\n**Détails :**\n- Doit être composé de caractères a-z, A-Z, 0-9, ou contenir des underscores et des tirets\n- Longueur maximale de 64 caractères"
              },
              "description": {
                "type": "string",
                "description": "Description de la fonction, aide le modèle à comprendre quand et comment appeler cette fonction"
              },
              "parameters": {
                "type": "object",
                "description": "Paramètres d'entrée de la fonction, décrits comme un objet JSON Schema\n\n**Détails** :\n- Omettre `parameters` définit une fonction avec une liste de paramètres vide"
              },
              "strict": {
                "type": "boolean",
                "description": "Activer le mode strict (Beta)\n\n**Détails** :\n- Lorsqu'il est défini sur `true`, l'API utilisera le mode strict pour les appels de fonction\n- Garantit que la sortie est toujours conforme à la définition JSON Schema de la fonction",
                "default": false
              }
            }
          }
        }
      },
      "ChatCompletionResponse": {
        "type": "object",
        "properties": {
          "id": {
            "type": "string",
            "description": "Identifiant unique pour la complétion de chat",
            "example": "930c60df-bf64-41c9-a88e-3ec75f81e00e"
          },
          "model": {
            "type": "string",
            "description": "Nom du modèle réellement utilisé",
            "example": "deepseek-chat"
          },
          "object": {
            "type": "string",
            "enum": [
              "chat.completion"
            ],
            "description": "Type de réponse",
            "example": "chat.completion"
          },
          "created": {
            "type": "integer",
            "description": "Horodatage de création",
            "example": 1770617860
          },
          "choices": {
            "type": "array",
            "description": "Liste des choix de complétion de chat",
            "items": {
              "$ref": "#/components/schemas/Choice"
            }
          },
          "usage": {
            "$ref": "#/components/schemas/Usage"
          },
          "system_fingerprint": {
            "type": "string",
            "description": "Identifiant d'empreinte système",
            "example": "fp_eaab8d114b_prod0820_fp8_kvcache"
          }
        }
      },
      "Choice": {
        "type": "object",
        "properties": {
          "index": {
            "type": "integer",
            "description": "Index du choix",
            "example": 0
          },
          "message": {
            "$ref": "#/components/schemas/AssistantMessage"
          },
          "finish_reason": {
            "type": "string",
            "description": "Raison de fin\n\n- `stop` : Achèvement naturel ou séquence d'arrêt atteinte\n- `length` : Limite maximale de tokens atteinte\n- `content_filter` : Sortie filtrée par la politique de sécurité\n- `tool_calls` : Le modèle a appelé un outil\n- `insufficient_system_resource` : Contraintes de ressources backend",
            "enum": [
              "stop",
              "length",
              "content_filter",
              "tool_calls",
              "insufficient_system_resource"
            ],
            "example": "stop"
          }
        }
      },
      "AssistantMessage": {
        "type": "object",
        "properties": {
          "role": {
            "type": "string",
            "description": "Rôle de l'expéditeur du message",
            "enum": [
              "assistant"
            ],
            "example": "assistant"
          },
          "content": {
            "type": "string",
            "description": "Contenu de la réponse IA",
            "example": "Hello! I'm DeepSeek, a powerful AI assistant. I excel at general conversation, code generation, mathematical reasoning and many other tasks."
          },
          "reasoning_content": {
            "type": "string",
            "description": "Contenu du processus de raisonnement (retourné uniquement par le modèle `deepseek-reasoner`)\n\n**Détails** :\n- Contient le processus de chaîne de pensée du modèle\n- Retourné uniquement lors de l'utilisation du modèle `deepseek-reasoner`",
            "example": "Let me analyze this problem..."
          },
          "tool_calls": {
            "type": "array",
            "description": "Liste d'appels d'outils (retournée lorsque le modèle décide d'appeler un outil)",
            "items": {
              "type": "object",
              "properties": {
                "id": {
                  "type": "string",
                  "description": "Identifiant unique pour l'appel d'outil"
                },
                "type": {
                  "type": "string",
                  "enum": [
                    "function"
                  ]
                },
                "function": {
                  "type": "object",
                  "properties": {
                    "name": {
                      "type": "string",
                      "description": "Nom de la fonction appelée"
                    },
                    "arguments": {
                      "type": "string",
                      "description": "Arguments de fonction (chaîne JSON)"
                    }
                  }
                }
              }
            }
          }
        }
      },
      "Usage": {
        "type": "object",
        "description": "Statistiques d'utilisation des jetons",
        "properties": {
          "prompt_tokens": {
            "type": "integer",
            "description": "Nombre de tokens dans l'entrée",
            "example": 16
          },
          "completion_tokens": {
            "type": "integer",
            "description": "Nombre de tokens dans la sortie",
            "example": 10
          },
          "total_tokens": {
            "type": "integer",
            "description": "Nombre total de jetons",
            "example": 26
          },
          "prompt_cache_hit_tokens": {
            "type": "integer",
            "description": "Nombre de tokens en cache trouvés dans l'entrée",
            "example": 0
          },
          "prompt_cache_miss_tokens": {
            "type": "integer",
            "description": "Nombre de tokens non trouvés en cache dans l'entrée",
            "example": 16
          }
        }
      },
      "ErrorResponse": {
        "type": "object",
        "properties": {
          "error": {
            "type": "object",
            "properties": {
              "code": {
                "type": "integer",
                "description": "Code d'erreur de statut HTTP"
              },
              "message": {
                "type": "string",
                "description": "Description de l'erreur"
              },
              "type": {
                "type": "string",
                "description": "Type d'erreur"
              },
              "param": {
                "type": "string",
                "description": "Nom du paramètre concerné"
              }
            }
          }
        }
      }
    },
    "securitySchemes": {
      "bearerAuth": {
        "type": "http",
        "scheme": "bearer",
        "description": "##Toutes les API nécessitent une authentification Bearer Token##\n\n**Obtenir une clé API :**\n\nVisitez la [Page de gestion des clés API](https://evolink.ai/dashboard/keys) pour obtenir votre clé API\n\n**Ajouter à l'en-tête de requête :**\n```\nAuthorization: Bearer YOUR_API_KEY\n```"
      }
    }
  },
  "tags": [
    {
      "name": "Complétion de chat",
      "description": "APIs liées à la complétion de chat IA"
    }
  ]
}